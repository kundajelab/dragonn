{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: \n",
    "#* threshold motif scores at 0 \n",
    "#* PRC curves --> Merged in this notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# How to train your DragoNN tutorial 3: \n",
    "## Interpreting features induced by DNN's across multiple types of motif grammars \n",
    "\n",
    "This tutorial is a supplement to the DragoNN manuscript and follows figure 7 in the manuscript. \n",
    "\n",
    "This tutorial will take 1 hour  if executed on a GPU. \n",
    "\n",
    "Please complete \"Primer Tutorial 1- Exploring model architectures for a homotypic motif density simulation\" prior to completing this tutorial. \n",
    "\n",
    "The architectures used in this tutorial were determined as optimal by hyperparameter grid search in \"Primer Tutorial 3 - CNN Hyperparameter Tuning via Grid Search\"\n",
    "\n",
    "\n",
    "## Outline<a name='outline'>\n",
    "<ol>\n",
    "    <li><a href=#1>How to use this tutorial</a></li>\n",
    "    <li><a href=#2>Defining helper functions for model training and interpretation</a></li>\n",
    "    TODO: explain reference options. \n",
    "    <li><a href=#3>Simulating training data with simdna: Review of Tutorial 1</a></li>\n",
    "    <li><a href=#4>Single Motif</a></li>\n",
    "    <li><a href=#5>Homotypic motif density detection</a></li>\n",
    "    <li><a href=#6>Homotypic motif density localization</a></li>\n",
    "    <li><a href=#7>Multiple motifs (multi-task)</a></li>  \n",
    "    <li><a href=#8>Heterotypic motifs spatial grammar</a></li>\n",
    "    <li><a href=#9>Conclusions</a></li>\n",
    "</ol>\n",
    "Github issues on the dragonn repository with feedback, questions, and discussion are always welcome.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this tutorial<a name='1'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "This tutorial utilizes a Jupyter/IPython Notebook - an interactive computational enviroment that combines live code, visualizations, and explanatory text. The notebook is organized into a series of cells. You can run the next cell by cliking the play button:\n",
    "![play button](./tutorial_images/play_button.png)\n",
    "You can also run all cells in a series by clicking \"run all\" in the Cell drop-down menu:\n",
    "![play all button](./tutorial_images/play_all_button.png)\n",
    "Half of the cells in this tutorial contain code, the other half contain visualizations and explanatory text. Code, visualizations, and text in cells can be modified - you are encouraged to modify the code as you advance through the tutorial. You can inspect the implementation of a function used in a cell by following these steps:\n",
    "![inspecting code](./tutorial_images/inspecting_code.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the lines below if you are running this tutorial from Google Colab \n",
    "#!pip install dragonn>=0.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prepare for model training, we import the necessary functions and submodules from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Reshape, Dense, Activation, Flatten,BatchNormalization,Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta, SGD, RMSprop;\n",
    "import keras.losses;\n",
    "from keras.constraints import maxnorm;\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import EarlyStopping, History\n",
    "from keras import backend as K \n",
    "K.set_image_data_format('channels_last')\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading dragonn's tutorial utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dragonn tutorial utilities \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions for model training and interpretation  <a name='2'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of simulation, we will perform a consistent set of tasks: \n",
    "* Define the optimal model architecture, as determined in Tutorial 2. This architecture will be specific to the simulation used, so we don't write a universal helper function for this purpose. \n",
    "* Train the model on simulation data and visualize the model's learning curve on training and validation data. \n",
    "* Compute the model's performance on a held-out test set.\n",
    "* Visualize motif scores for a positive and negative example. \n",
    "* Perform in silico mutagenesis for a positive and negative example.\n",
    "* Compute DeepLIFT scores for a positive and negative example.\n",
    "\n",
    "To avoid writing the same code for each scenario, we define a series of helpers functions to perform the tasks above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.callbacks import * \n",
    "from dragonn.vis import plot_learning_curve\n",
    "\n",
    "def train_model(model,data):\n",
    "    #We define a custom callback to print training and validation metrics while training. \n",
    "    metrics_callback=MetricsCallback(train_data=(data.X_train,data.y_train),validation_data=(data.X_valid,data.y_valid))\n",
    "    \n",
    "    #Train the model \n",
    "    history=model.fit(x=data.X_train,\n",
    "                      y=data.y_train,\n",
    "                      batch_size=128,\n",
    "                      epochs=150,\n",
    "                      verbose=0,\n",
    "                      callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                metrics_callback],\n",
    "                                validation_data=(data.X_valid,data.y_valid))\n",
    "    \n",
    "    #Visualize the model's performance curve \n",
    "    plot_learning_curve(history)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute model performance on a held out test set \n",
    "def compute_performance(model,data):\n",
    "    test_predictions=model.predict(data.X_test)\n",
    "    ## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "    print(ClassificationResult(data.y_test,test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos_and_neg_samples(data,n=None):\n",
    "#split training, validation, test data into positive and negative subsets \n",
    "# if n is provided, the first n positive and negative samples will be selected from each split \n",
    "    if n is None: \n",
    "        n=data.shape[0]\n",
    "    train_pos_index=np.flatnonzero(data.y_train==1)\n",
    "    train_pos_X=data.X_train[train_pos_index][0:n]\n",
    "    train_neg_index=np.flatnonzero(data.y_train==0)\n",
    "    train_neg_X=data.X_train[train_neg_index][0:n]\n",
    "    \n",
    "    valid_pos_index=np.flatnonzero(data.y_valid==1)\n",
    "    valid_pos_X=data.X_valid[valid_pos_index][0:n]\n",
    "    valid_neg_index=np.flatnonzero(data.y_valid==0)\n",
    "    valid_neg_X=data.X_valid[valid_neg_index][0:n]\n",
    "    \n",
    "    test_pos_index=np.flatnonzero(data.y_test==1)\n",
    "    test_pos_X=data.X_test[test_pos_index][0:n]\n",
    "    test_neg_index=np.flatnonzero(data.y_test==0)\n",
    "    test_neg_X=data.X_test[test_neg_index][0:n]\n",
    "    \n",
    "    return train_pos_X,train_neg_X, valid_pos_X, valid_neg_X, test_pos_X, test_neg_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the full data analysis for a given dataset and model \n",
    "#Train the model, compute it's performance on a positive and negative data point \n",
    "from dragonn.interpret import * \n",
    "def analyze(model,data,pos_index,neg_index,outfname,motif_names,xlim_for_plot,n_to_interpret=None):\n",
    "    \n",
    "    '''\n",
    "    model -- keras model object \n",
    "    data -- simulated dataset object \n",
    "    pos_index -- numberical index of positive test example (within the data object) that should be interpreted \n",
    "    neg_index -- numberical index of negative test eample (within the data object) that should be interpreted \n",
    "    outfname -- name of output file to save the keras model \n",
    "    motif_names -- list of motif names used in the simulation \n",
    "    xlim_for_plot -- tuple indicating start and end x-coordinates of sequence example (0-indexed) to show in interpretation plot \n",
    "    n_to_interpet -- number of test samples to interpet\n",
    "    Returns: \n",
    "    pos_interpretation -- dictionary of interpretation metrics for positive examples in the test set \n",
    "    neg_interpretation -- dictionary of interpretation metrics for negative examples in the test set \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Train the model\n",
    "    model=train_model(model,data)\n",
    "    #Compute model performance on a held-out test set \n",
    "    compute_performance(model,data)\n",
    "    #save the model to an output file \n",
    "    model.save(outfname)\n",
    "    #Extract positive and negative examples for interpretation \n",
    "    train_pos_X,train_neg_X, valid_pos_X, valid_neg_X, test_pos_X, test_neg_X=extract_pos_and_neg_samples(data,n_to_interpret)\n",
    "    #Get the deepLIFT scoring function\n",
    "\n",
    "    #perform interpretation on the test set \n",
    "    test_pos_interpretations=multi_method_interpret(model,\n",
    "                                           test_pos_X,\n",
    "                                           0,\n",
    "                                           motif_names=motif_names,\n",
    "                                           generate_plots=False)\n",
    "    \n",
    "    test_neg_interpretations=multi_method_interpret(model,\n",
    "                                           test_neg_X,\n",
    "                                           0,\n",
    "                                           motif_names=motif_names,\n",
    "                                           generate_plots=False)\n",
    "    \n",
    "    return test_pos_X,test_neg_X,test_pos_interpretations,test_neg_interpretations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set a random seed to ensure that all analyses in this tutorial are reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure our results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting simulation data <a name='3'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "\n",
    "DragoNN provides a set of simulation functions. Let's use the **print_available_simulations** function to examine the list of simulations supported by DragoNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulate_differential_accessibility\n",
      "simulate_heterodimer_grammar\n",
      "simulate_motif_counting\n",
      "simulate_motif_density_localization\n",
      "simulate_multi_motif_embedding\n",
      "simulate_single_motif_detection\n"
     ]
    }
   ],
   "source": [
    "from dragonn.simulations import * \n",
    "print_available_simulations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Motif <a name='4'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with single motif detection of the TAL1_known4 motif: \n",
    "\n",
    "![play button](./tutorial_images/TAL1_known4.png)\n",
    "Let's find out what parameters are needed for the simulation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Simulates two classes of seqeuences:\n",
      "        - Positive class sequence with a motif\n",
      "          embedded anywhere in the sequence\n",
      "        - Negative class sequence without the motif\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    motif_name : str\n",
      "        encode motif name\n",
      "    seq_length : int\n",
      "        length of sequence\n",
      "    num_pos : int\n",
      "        number of positive class sequences\n",
      "    num_neg : int\n",
      "        number of negative class sequences\n",
      "    GC_fraction : float\n",
      "        GC fraction in background sequence\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    sequence_arr : 1darray\n",
      "        Array with sequence strings.\n",
      "    y : 1darray\n",
      "        Array with positive/negative class labels.\n",
      "    embedding_arr: 1darray\n",
      "        Array of embedding objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print_simulation_info(\"simulate_single_motif_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this binary simulation task, we simulate a negative set of 10K 500 bp random sequences and a positive set of 10K 500 bp random sequences with one instance of the TAL1 motif randomly embedded at any position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define simulation parameters \n",
    "tal1_parameters = {\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 500, \n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "\n",
    "#Get simulation data \n",
    "tal1_data = get_simulation_data(\"simulate_single_motif_detection\",\n",
    "                                      tal1_parameters,\n",
    "                                      validation_set_size=3200, test_set_size=4000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the convolutional neural network model architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 23:58:23.706808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-29 23:58:26.502982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11487 MB memory:  -> device: 0, name: NVIDIA GeForce GTX TITAN X, pci bus id: 0000:09:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "source": [
    "#Define the optimal model architecture in keras (Refer to Primer Tutorial 2)\n",
    "tal1_model=Sequential() \n",
    "tal1_model.add(Conv2D(filters=10,kernel_size=(1,15),input_shape=tal1_data.X_train.shape[1::]))\n",
    "tal1_model.add(Activation('relu'))\n",
    "tal1_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "tal1_model.add(Flatten())\n",
    "tal1_model.add(Dense(1))\n",
    "tal1_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "tal1_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 23:58:28.320993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11487 MB memory:  -> device: 0, name: NVIDIA GeForce GTX TITAN X, pci bus id: 0000:09:00.0, compute capability: 5.2\n",
      "2022-06-29 23:58:28.356161: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tal1_model=load_model(\"tut3_single_motif_detection.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 'motif_scan' value\n",
      "getting 'ism' value\n",
      "ISM: task:0 sample:0\n",
      "getting 'input_grad' value\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "getting 'deepshap' value\n",
      "Done 0 examples of 1\n",
      "getting 'motif_scan' value\n",
      "getting 'ism' value\n",
      "ISM: task:0 sample:0\n",
      "getting 'input_grad' value\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "getting 'deepshap' value\n",
      "Done 0 examples of 1\n"
     ]
    }
   ],
   "source": [
    "#note: ISM is quite slow, so we select 50 samples for interpretation \n",
    "n_to_interpret=1\n",
    "single_motif_pos_X,single_motif_neg_X, single_motif_pos_interpretations, single_motif_neg_interpretations = analyze(tal1_model,tal1_data,1,1,\"tut3_single_motif_detection.hdf5\",[\"TAL1_known4\"],(0,500),n_to_interpret=n_to_interpret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in to the portion of the interpretation track with the strongest signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from dragonn.vis import * \n",
    "plot_all_interpretations([single_motif_pos_interpretations],\n",
    "                         single_motif_pos_X,\n",
    "                         title=\"Single Motif, Positive\",\n",
    "                         index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_interpretations([single_motif_neg_interpretations],\n",
    "                         single_motif_neg_X,\n",
    "                         title=\"Single Motif, Negative\",\n",
    "                         index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.positional_prc import * \n",
    "motif_score_posPRC=positionalPRC(tal1_data.test_embeddings[0:n_to_interpret],single_motif_pos_interpretations['motif_scan'])\n",
    "motif_score_posPRC=positionalPRC(tal1_data.test_embeddings[0:n_to_interpret],single_motif_pos_interpretations['motif_scan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dragonn.vis import plot_positionalPRC\n",
    "plot_positionalPRC(motif_score_posPRC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homotypic motif density detection <a name='5'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define simulation parameters \n",
    "density_detection_parameters={\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 500,\n",
    "    \"neg_counts\":[0,2],\n",
    "    \"pos_counts\":[3,5],\n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\":0.4\n",
    "}\n",
    "\n",
    "#Get simulation data\n",
    "density_detection_data=get_simulation_data(\"simulate_motif_counting\",\n",
    "                               density_detection_parameters,\n",
    "                               validation_set_size=3200,test_set_size=4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimal model architecture in keras (Refer to Primer Tutorial 2)\n",
    "density_detection_model=Sequential() \n",
    "density_detection_model.add(Conv2D(filters=10,kernel_size=(1,15),input_shape=density_detection_data.X_train.shape[1::]))\n",
    "density_detection_model.add(Activation('relu'))\n",
    "density_detection_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "density_detection_model.add(Flatten())\n",
    "density_detection_model.add(Dense(1))\n",
    "density_detection_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "density_detection_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_detection_pos_X,density_detection_neg_X,density_detection_pos_interpretations,density_detection_neg_interpetations=analyze(density_detection_model,density_detection_data,\n",
    "                                             1,\n",
    "                                             1,\n",
    "                                             \"tut3_density_detection.hdf5\",\n",
    "                                             [\"TAL1_known4\"],\n",
    "                                             (0,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homotypic motif density localization <a name='6'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define simulation parameters \n",
    "density_localization_parameters = {\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 1000,\n",
    "    \"center_size\": 150,\n",
    "    \"min_motif_counts\": 2,\n",
    "    \"max_motif_counts\": 4, \n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "\n",
    "#Get simulation data\n",
    "density_localization_data=get_simulation_data(\"simulate_motif_density_localization\",\n",
    "                               density_localization_parameters,\n",
    "                               validation_set_size=3200,test_set_size=4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimal model architecture in keras (Refer to Primer Tutorial 2)\n",
    "density_localization_model=Sequential() \n",
    "density_localization_model.add(Conv2D(filters=5,kernel_size=(1,10),input_shape=density_localization_data.X_train.shape[1::]))\n",
    "density_localization_model.add(Activation('relu'))\n",
    "density_localization_model.add(MaxPooling2D(pool_size=(1,10)))\n",
    "density_localization_model.add(Flatten())\n",
    "density_localization_model.add(Dense(1))\n",
    "density_localization_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "density_localization_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X, neg_X, ism_pos, ism_neg, gradinput_pos, gradinput_neg, dl_pos, dl_neg=analyze(density_localization_model,density_localization_data,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seq_importance(dl_pos,pos_X,xlim=(220,275),title=\"Positive\")\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(220,275),title=\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple motifs (multi-task)<a name='7'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define simulation parameters \n",
    "multi_motif_parameters = {\n",
    "    \"motif_names\": [\"CTCF_known1\",\"ZNF143_known2\",\"SIX5_known1\"],\n",
    "    \"seq_length\": 500,\n",
    "    \"min_num_motifs\": 0,\n",
    "    \"max_num_motifs\": 1, \n",
    "    \"num_seqs\": 20000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "\n",
    "#Get simulation data\n",
    "multi_motif_data=get_simulation_data(\"simulate_multi_motif_embedding\",\n",
    "                               multi_motif_parameters,\n",
    "                               validation_set_size=3200,test_set_size=4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimal model architecture in keras (Refer to Primer Tutorial 2)\n",
    "multi_motif_model=Sequential() \n",
    "multi_motif_model.add(Conv2D(filters=20,kernel_size=(1,20),input_shape=multi_motif_data.X_train.shape[1::]))\n",
    "multi_motif_model.add(Activation('relu'))\n",
    "multi_motif_model.add(MaxPooling2D(pool_size=(1,10)))\n",
    "multi_motif_model.add(Flatten())\n",
    "multi_motif_model.add(Dense(3))\n",
    "multi_motif_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "multi_motif_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X, neg_X, ism_pos, ism_neg, gradinput_pos, gradinput_neg, dl_pos, dl_neg=analyze(multi_motif_model, multi_motif_data,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seq_importance(dl_pos,pos_X,xlim=(220,275),title=\"Positive\")\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(220,275),title=\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterotypic motifs spatial grammar<a name='8'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define simulation parameters \n",
    "heterodimer_parameters = {\n",
    "    \"motif1\": \"SPI1_known4\",\n",
    "    \"motif2\": \"IRF_known1\",\n",
    "    \"seq_length\": 500,\n",
    "    \"min_spacing\": 2,\n",
    "    \"max_spacing\": 5, \n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "\n",
    "#Get simulation data\n",
    "heterodimer_data=get_simulation_data(\"simulate_heterodimer_grammar\",\n",
    "                               heterodimer_parameters,\n",
    "                               validation_set_size=3200,test_set_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heterodimer_model=Sequential()\n",
    "heterodimer_model.add(Conv2D(filters=15,kernel_size=(1,15),input_shape=input_shape))\n",
    "heterodimer_model.add(Activation(\"relu\"))\n",
    "heterodimer_model.add(Conv2D(filters=15,kernel_size=(1,15),input_shape=input_shape))\n",
    "heterodimer_model.add(Activation(\"relu\"))\n",
    "heterodimer_model.add(Conv2D(filters=15,kernel_size=(1,15),input_shape=input_shape))\n",
    "heterodimer_model.add(Activation(\"relu\"))\n",
    "heterodimer_model.add(MaxPooling2D(pool_size=(1,35)))    \n",
    "heterodimer_model.add(Flatten())\n",
    "heterodimer_model.add(Dense(num_tasks))\n",
    "heterodimer_model.add(Activation(\"sigmoid\"))\n",
    "heterodimer_model.compile(optimizer='adam',loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X, neg_X, ism_pos, ism_neg, gradinput_pos, gradinput_neg, dl_pos, dl_neg=analyze(heterodimer_model,heterodimer_data,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seq_importance(dl_pos,pos_X,xlim=(220,275),title=\"Positive\")\n",
    "plot_seq_importance(dl_neg,neg_X,xlim=(220,275),title=\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions<a name='9'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dragonn",
   "language": "python",
   "name": "dragonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
