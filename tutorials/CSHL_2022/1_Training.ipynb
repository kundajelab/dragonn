{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APNfq3knhfZg"
   },
   "source": [
    "# How to train your DragoNN: \n",
    "## Exploring convolutional neural network (CNN) architectures for simulated genomic data\n",
    "\n",
    "This tutorial will take <1 hour if executed on a GPU. \n",
    "\n",
    "## Outline<a name='outline'>\n",
    "<ol>\n",
    "    <li><a href=#1>How to use this tutorial</a></li>\n",
    "    <li><a href=#2>Review of patterns in transcription factor binding sites</a></li>\n",
    "    <li><a href=#3>Learning to localize homotypic motif density</a></li>\n",
    "    <li><a href=#4>Simulate training data with simdna</a></li>  \n",
    "    <li><a href=#4.5>Running dragonn on your own data: starting with FASTA files</a></li>\n",
    "    <li><a href=#5>Defining CNN architecture</a></li>\n",
    "    <li><a href=#6>Single layer, single filter model</a></li>\n",
    "    <li><a href=#7>Single layer, multiple filter model</a></li>\n",
    "    <li><a href=#9>For further exploration</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NixF5bW3hfZg"
   },
   "source": [
    "## How to use this tutorial<a name='1'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "This tutorial utilizes a Google Colaboratory Notebook - an interactive computational enviroment that combines live code, visualizations, and explanatory text. The notebook is organized into a series of cells. \n",
    "\n",
    "The first thing we do is set our Runtime to use Python3 and GPU. \n",
    "\n",
    "![ChangeRuntime](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/ChangeRuntime.png?raw=true)\n",
    "\n",
    "![RuntimeType.png](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/RuntimeType.png?raw=1)\n",
    "\n",
    "Now that we set our Runtime, we can execute the cells in the notebook. You can execute the cells one at a time by clicking inside of them and pressing SHIFT+enter. Alternatively, you can run all the cells by clicking the \"Run All\" button, as demonstrated below. \n",
    "\n",
    "![RunAllColab](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/RunAllCollab.png?raw=1)\n",
    "\n",
    "\n",
    "You can run the next cell by cliking the play button:\n",
    "\n",
    "![RunCellArrow](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/RunCellArrow.png?raw=1)\n",
    "\n",
    "Half of the cells in this tutorial contain code, the other half contain visualizations and explanatory text. Code, visualizations, and text in cells can be modified - you are encouraged to modify the code as you advance through the tutorial. You can inspect the implementation of a function used in a cell by following these steps:\n",
    "\n",
    "![inspecting code](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/inspecting_code.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWLcVFDXzihK"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running locally\n",
    "# import sys\n",
    "# sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wORsai47hfZi"
   },
   "outputs": [],
   "source": [
    "# run the lines below if you are running this tutorial from Google Colab \n",
    "# RESTART NOTEBOOK AFTER RUNNING THIS\n",
    "!pip install git+https://github.com/kundajelab/dragonn.git@icts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oBUEZ7wMJkq"
   },
   "outputs": [],
   "source": [
    "!pip show tensorflow\n",
    "!pip show dragonn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSaW2fD2hfZk"
   },
   "outputs": [],
   "source": [
    "# Making sure our results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1234)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-bvAg5-hfZn"
   },
   "source": [
    "We start by loading dragonn's tutorial utilities and reviewing properties of regulatory sequence that transcription factors bind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e2J6BZ-hfZo"
   },
   "outputs": [],
   "source": [
    "# load dragonn tutorial utilities \n",
    "from matplotlib import pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e3bYhMBhfZr"
   },
   "source": [
    "## Key properties of regulatory DNA sequences <a name='2'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "![sequence properties 1](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/sequence_properties_1.jpg?raw=1)\n",
    "![sequence properties 2](https://github.com/kundajelab/dragonn/blob/master/paper_supplement/primer_tutorial_images/sequence_properties_2.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga1AXeKXhfZs"
   },
   "source": [
    "## Learning to localize homotypic motif density <a name='3'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "In this tutorial we will learn how to localize a homotypic motif cluster. We will simulate a positive set of sequences with multiple instances of a motif in the center and a negative set of sequences with multiple motif instances positioned anywhere in the sequence:\n",
    "![homotypic motif density localization](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/homotypic_motif_density_localization.jpg?raw=1)\n",
    "We will then train a binary classification model to classify the simulated sequences. To solve this task, the model will need to learn the motif pattern and whether instances of that pattern are present in the central part of the sequence.\n",
    "\n",
    "![classification task](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/homotypic_motif_density_localization_task.jpg?raw=1)\n",
    "\n",
    "We start by getting the simulation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5-27zcHhfZt"
   },
   "source": [
    "## Getting simulation data <a name='4'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "\n",
    "DragoNN provides a set of simulation functions. We will use the **simulate_motif_density_localization** function to simulate homotypic motif density localization. First, we obtain documentation for the simulation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwUscf6NzihY"
   },
   "outputs": [],
   "source": [
    "from dragonn.simulations import * \n",
    "from dragonn.vis import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kv-SkzqXhfZt"
   },
   "outputs": [],
   "source": [
    "print_simulation_info(\"simulate_motif_density_localization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CzKV_rDhfZw"
   },
   "source": [
    "Next, we define parameters for a TAL1 motif density localization in 1000bp long sequence, with 0.4 GC fraction, and 2-4 instances of the motif in the central 150bp for the positive sequences. We simulate a total of 3000 positive and 3000 negative sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CgzxAhShfZw"
   },
   "outputs": [],
   "source": [
    "motif_density_localization_simulation_parameters = {\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 1000,\n",
    "    \"center_size\": 150,\n",
    "    \"min_motif_counts\": 2,\n",
    "    \"max_motif_counts\": 4, \n",
    "    \"num_pos\": 3000,\n",
    "    \"num_neg\": 3000,\n",
    "    \"GC_fraction\": 0.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HpAcK0mhfZz"
   },
   "source": [
    "We get the simulation data by calling the **get_simulation_data** function with the simulation name and the simulation parameters as inputs. 1000 sequences are held out for a test set, 1000 sequences for a validation set, and the remaining 4000 sequences are in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8cJCmy9hfZ0"
   },
   "outputs": [],
   "source": [
    "simulation_data = get_simulation_data(\"simulate_motif_density_localization\",\n",
    "                                      motif_density_localization_simulation_parameters,\n",
    "                                      validation_set_size=1000, test_set_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e-3Sk0Azihm"
   },
   "source": [
    "simulation_data provides training, validation, and test sets of input sequences X and sequence labels y. The inputs X are matrices with a one-hot-encoding of the sequences:\n",
    "\n",
    "<img src=\"https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/one_hot_encoding.png?raw=1\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8fJ0c1Mzihm"
   },
   "source": [
    "Simulation data is an object. It contains an attribute called X_train that is a numpy array of 4 dimensions. We can call the \"shape\" function on X_train to get it's dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuEbg6Ftzihn"
   },
   "outputs": [],
   "source": [
    "simulation_data.X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McjA51Uk2ehG"
   },
   "source": [
    "Here are the first 10bp of a sequence in our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uGOwNHTziht"
   },
   "outputs": [],
   "source": [
    "#The first dimension indicates the index of the training samples. \n",
    "# The second dimension is 1, and is only necessary because we are \n",
    "# performing 2D convolutions. We could omit this \"dummy\" dimension if\n",
    "# we used 1D convolutions. \n",
    "# The third dimension indicates the base index. \n",
    "# The fourth dimension indicates the base pair channels: A,C,G,T. \n",
    "\n",
    "simulation_data.X_train[0, :, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLupnMwqhfZ-"
   },
   "source": [
    "We can convert this one-hot-encoded matrix back into a DNA string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05S6ivnThfZ-"
   },
   "outputs": [],
   "source": [
    "from dragonn.utils import *\n",
    "get_sequence_strings(simulation_data.X_train)[0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrtwHPxthfaA"
   },
   "source": [
    "Let's examine the shape of training, validation, and test matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzNTlHQmhfaB"
   },
   "outputs": [],
   "source": [
    "print(simulation_data.X_train.shape)\n",
    "print(simulation_data.y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J89jB_BFhfaE"
   },
   "outputs": [],
   "source": [
    "print(simulation_data.X_valid.shape)\n",
    "print(simulation_data.y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6tHqiBEhfaH"
   },
   "outputs": [],
   "source": [
    "print(simulation_data.X_test.shape)\n",
    "print(simulation_data.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zSjm7LWziiG"
   },
   "source": [
    "## Running dragonn on your own data: starting with FASTA files <a name='4.5'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2G6qRmZziiH"
   },
   "source": [
    "If you are running Dragonn on your own data, you can provide data in FASTA sequence format. We recommend generating 6 fasta files for model training: \n",
    "* Training positives \n",
    "* Training negatives \n",
    "* Validation positives \n",
    "* Validation negatives \n",
    "* Test positives \n",
    "* Test negatives \n",
    "\n",
    "To indicate how this could be done, we export the one-hot-encoded matrices from **simulation_data** to a FASTA file, and then show how this fasta file could be loaded back to a one-hot-encoded matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsA3TIC0ziiI"
   },
   "outputs": [],
   "source": [
    "from dragonn.utils import fasta_from_onehot\n",
    "\n",
    "#get the indices of positive and negative sequences in the training, validation, and test sets \n",
    "train_pos=np.nonzero(simulation_data.y_train==True)\n",
    "train_neg=np.nonzero(simulation_data.y_train==False)\n",
    "valid_pos=np.nonzero(simulation_data.y_valid==True)\n",
    "valid_neg=np.nonzero(simulation_data.y_valid==False)\n",
    "test_pos=np.nonzero(simulation_data.y_test==True)\n",
    "test_neg=np.nonzero(simulation_data.y_test==False)\n",
    "\n",
    "#Generate gzipped  fasta files -- it is always a good idea to gzip your fasta files. This is less \n",
    "# important for our tiny example files, but becomes more relevant as the size of the files increases. \n",
    "# The fasta_from_onehot function gzips output fasta files. \n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_train[train_pos],axis=1),\"X.train.pos.fasta.gz\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_valid[valid_pos],axis=1),\"X.valid.pos.fasta.gz\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_test[test_pos],axis=1),\"X.test.pos.fasta.gz\")\n",
    "\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_train[train_neg],axis=1),\"X.train.neg.fasta.gz\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_valid[valid_neg],axis=1),\"X.valid.neg.fasta.gz\")\n",
    "fasta_from_onehot(np.expand_dims(simulation_data.X_test[test_neg],axis=1),\"X.test.neg.fasta.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tNuyVpaziiK"
   },
   "source": [
    "Let's examine \"X.train.pos.fasta.gz\" to verify that it's in the standard gzipped FASTA format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f16lnk8cziiK"
   },
   "outputs": [],
   "source": [
    "! zcat X.train.pos.fasta.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGFUpDVPziiO"
   },
   "source": [
    "We can then load fasta format data to generate training, validation, and test splits for our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F1CWZ8iziiO"
   },
   "outputs": [],
   "source": [
    "from dragonn.utils import encode_fasta_sequences\n",
    "X_train_pos=encode_fasta_sequences(\"X.train.pos.fasta.gz\")\n",
    "X_train_neg=encode_fasta_sequences(\"X.train.neg.fasta.gz\")\n",
    "X_valid_pos=encode_fasta_sequences(\"X.valid.pos.fasta.gz\")\n",
    "X_valid_neg=encode_fasta_sequences(\"X.valid.neg.fasta.gz\")\n",
    "X_test_pos=encode_fasta_sequences(\"X.test.pos.fasta.gz\")\n",
    "X_test_neg=encode_fasta_sequences(\"X.test.neg.fasta.gz\")\n",
    "\n",
    "X_train=np.concatenate((X_train_pos,X_train_neg),axis=0)\n",
    "X_valid=np.concatenate((X_valid_pos,X_valid_neg),axis=0)\n",
    "X_test=np.concatenate((X_test_pos,X_test_neg),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcSZAyGdziiQ"
   },
   "outputs": [],
   "source": [
    "y_train=np.concatenate((np.ones(X_train_pos.shape[0]),\n",
    "                        np.zeros(X_train_neg.shape[0])))\n",
    "y_valid=np.concatenate((np.ones(X_valid_pos.shape[0]),\n",
    "                        np.zeros(X_valid_neg.shape[0])))\n",
    "y_test=np.concatenate((np.ones(X_test_pos.shape[0]),\n",
    "                        np.zeros(X_test_neg.shape[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYOwbRPqziiS"
   },
   "source": [
    "Now, having read in the FASTA files, converted them to one-hot-encoded matrices, and defined label vectors, we are ready to train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giRBRUbEhfaK"
   },
   "source": [
    "# Defining the convolutional neural network model architecture  <a name='5'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "A locally connected linear unit in a CNN model can represent a PWM (part a). A sequence PWM score is obtained by multiplying the PWM across the sequence, thresholding the PWM scores, and taking the max (part b). A PWM score can also be computed by a CNN model with tiled, locally connected linear units, amounting to a convolutional layer with a single convolutional filter representing the PWM, followed by ReLU thresholding and maxpooling (part c).\n",
    "    \n",
    "![dragonn vs pssm](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/dragonn_and_pssm.jpg?raw=1)\n",
    "\n",
    "\n",
    "By utilizing multiple convolutional layers with multiple convolutional filters, CNN's can represent a wide range of sequence features in a compositional fashion:\n",
    "    \n",
    "![dragonn model figure](https://github.com/kundajelab/dragonn/blob/cshl/tutorials/tutorial_images/dragonn_model_figure.png?raw=1)\n",
    "\n",
    "\n",
    "We will use the deep learning library [keras](http://keras.io/) which is a high level API for  [TensorFlow](https://github.com/tensorflow/tensorflow) framework to generate and train the CNN models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMEgqp-bhfaL"
   },
   "outputs": [],
   "source": [
    "# To prepare for model training, we import the necessary functions and submodules from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Reshape, Dense, Activation, Flatten,Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80GBS3CFhfaN",
    "tags": []
   },
   "source": [
    "# Single layer, single filter model <a name='6'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfS72LrxhfaN"
   },
   "source": [
    "We define a simple DragoNN model with one convolutional layer with one convolutional filter, followed by maxpooling of width 35. \n",
    "\n",
    "The model parameters are: \n",
    "\n",
    "* Input sequence length 1000 \n",
    "* 1 filter: this is a neuron that acts as a local pattern detector on the input profile. \n",
    "* Convolutional filter width =  10: this metric defines the dimension of the filter weights; the model scans the entire input profile for a particular pattern encoded by the weights of the filter. \n",
    "* Max pool of width 35: computes the maximum value per-channel in sliding windows of size 35. We add the pooling layer becase DNA sequences are typically sparse in terms of the number of positions in the sequence that harbor TF motifs. The pooling layer allows us to reduce the size of the output profile of convolutional layers by employing summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "1ikMRDXRhfaO",
    "outputId": "058e4a1e-a694-4372-9ceb-fe73b002fecc"
   },
   "outputs": [],
   "source": [
    "#Define the model architecture in keras\n",
    "one_filter_keras_model=Sequential() \n",
    "one_filter_keras_model.add(Conv2D(filters=1,kernel_size=(1,10),padding=\"same\",input_shape=simulation_data.X_train.shape[1::]))\n",
    "one_filter_keras_model.add(BatchNormalization(axis=-1))\n",
    "one_filter_keras_model.add(Activation('relu'))\n",
    "one_filter_keras_model.add(MaxPooling2D(pool_size=(1,35)))\n",
    "one_filter_keras_model.add(Flatten())\n",
    "one_filter_keras_model.add(Dense(1))\n",
    "one_filter_keras_model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "_JhL10vzhfaQ",
    "outputId": "1b6782fc-3479-4ff5-8c9d-db807f56ec9d"
   },
   "outputs": [],
   "source": [
    "one_filter_keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rzKZVoNhfaS"
   },
   "outputs": [],
   "source": [
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "one_filter_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xwSZhvVhfaV"
   },
   "source": [
    "We train the model for 150 epochs, with an early stopping criterion -- if the loss on the validation set does not improve for five consecutive epochs, the training is halted. In each epoch, the one_filter_dragonn performed a complete pass over the training data, and updated its parameters to minimize the loss, which quantifies the error in the model predictions. After each epoch, the performance metrics for the one_filter_dragonn on the validation data were stored. \n",
    "\n",
    "The performance metrics include balanced accuracy, area under the receiver-operating curve ([auROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)), are under the precision-recall curve ([auPRC](https://en.wikipedia.org/wiki/Precision_and_recall)), and recall for multiple false discovery rates  (Recall at [FDR](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjRCE1JJhfaV"
   },
   "outputs": [],
   "source": [
    "from dragonn.callbacks import * \n",
    "#We define a custom callback to print training and validation metrics while training. \n",
    "metrics_callback=MetricsCallback(train_data=(simulation_data.X_train,simulation_data.y_train),\n",
    "                                 validation_data=(simulation_data.X_valid,simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u11Aj6ko2Gyv"
   },
   "source": [
    "We now proceed to train the model. We do this with the keras \"fit\" function. The \"fit\" function has a few key parameters: \n",
    "\n",
    "* **batch_size** -- the number of training and validation samples to be propagated through the network simultaneously. \n",
    "* **epochs** -- An epoch is a measure of the number of times all of the training vectors are used once to update the weights. For batch training all of the training samples pass through the learning algorithm simultaneously in one epoch before weights are updated.\n",
    "* **callbacks** -- Keras callbacks return information from a training algorithm while training is taking place. A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\n",
    "* **EarlyStopping** -- a Keras callback that gets called at the end of each epoch. If the loss has not decreased for a consecutive n epochs, where n is referred to as the patience, the training is interrupted. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaBJrS2Qhfal"
   },
   "source": [
    "## Visualize the intial parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWMTRBqJhfal"
   },
   "source": [
    "Next, let's visualize the randomly initialized weights in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u71ItwHBhfan"
   },
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwx8sbtuhfan",
    "outputId": "38a48e3a-680c-4b4f-fdcd-3dbaf5a1bf62"
   },
   "outputs": [],
   "source": [
    "plot_model_weights(one_filter_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9Ja44dfhfau"
   },
   "source": [
    "### Convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v541M5mhfav"
   },
   "outputs": [],
   "source": [
    "W_conv, b_conv = one_filter_keras_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuBSKMy-hfax",
    "outputId": "494331c0-6df0-4a67-fb23-18bd7a0795c9"
   },
   "outputs": [],
   "source": [
    "W_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWVP0eEPhfay",
    "outputId": "27c7dd17-4c46-4a8c-d248-295b7c13c050"
   },
   "outputs": [],
   "source": [
    "b_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRjf1T--hfa0",
    "outputId": "cce723b4-8b82-4b71-831a-9b63b3dd9d1d"
   },
   "outputs": [],
   "source": [
    "plot_filters(one_filter_keras_model, simulation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "eJT2c7XFhfaX",
    "outputId": "51b2bd94-5e15-489a-f954-093c8670e99e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_one_filter=one_filter_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSmch4Hghfaa"
   },
   "source": [
    "### Evaluate the model on the held-out test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCCsY5aohfab",
    "outputId": "4d6c7011-70f3-416c-8b77-66de5a996bb5"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=one_filter_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSYLNtjjhfaf"
   },
   "source": [
    "### Visualize the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtqlbmnmhfag"
   },
   "source": [
    "We can see that the validation loss is not decreasing and the auROC metric is not decreasing, which indicates this model is not learning. A simple plot of the learning curve, showing the loss function on the training and validation data over the course of training, demonstrates this visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLeHXZtGiqeB"
   },
   "outputs": [],
   "source": [
    "#import functions for visualization of data \n",
    "from dragonn.vis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WSa4OyEhfah",
    "outputId": "ea46fbca-1538-4611-9b76-3c9cc73534ce"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(history_one_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaBJrS2Qhfal"
   },
   "source": [
    "## Visualize the learned parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWMTRBqJhfal"
   },
   "source": [
    "Next, let's visualize the filter learned in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u71ItwHBhfan"
   },
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwx8sbtuhfan",
    "outputId": "38a48e3a-680c-4b4f-fdcd-3dbaf5a1bf62"
   },
   "outputs": [],
   "source": [
    "plot_model_weights(one_filter_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9Ja44dfhfau"
   },
   "source": [
    "### Convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v541M5mhfav"
   },
   "outputs": [],
   "source": [
    "W_conv, b_conv = one_filter_keras_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuBSKMy-hfax",
    "outputId": "494331c0-6df0-4a67-fb23-18bd7a0795c9"
   },
   "outputs": [],
   "source": [
    "W_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWVP0eEPhfay",
    "outputId": "27c7dd17-4c46-4a8c-d248-295b7c13c050"
   },
   "outputs": [],
   "source": [
    "b_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRjf1T--hfa0",
    "outputId": "cce723b4-8b82-4b71-831a-9b63b3dd9d1d"
   },
   "outputs": [],
   "source": [
    "plot_filters(one_filter_keras_model, simulation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80GBS3CFhfaN"
   },
   "source": [
    "# Single layer, multi-filter model <a name='7'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfS72LrxhfaN"
   },
   "source": [
    "We define a simple DragoNN model with one convolutional layer with 15 convolutional filters, followed by maxpooling of width 35. \n",
    "\n",
    "The model parameters are: \n",
    "\n",
    "* Input sequence length 1000 \n",
    "* 15 filter: there are neurons that act as  local pattern detectors on the input profile. \n",
    "* Convolutional filter width =  10: this metric defines the dimension of the filter weights; the model scans the entire input profile for a particular pattern encoded by the weights of the filter. \n",
    "* Max pool of width 35: computes the maximum value per-channel in sliding windows of size 35. We add the pooling layer becase DNA sequences are typically sparse in terms of the number of positions in the sequence that harbor TF motifs. The pooling layer allows us to reduce the size of the output profile of convolutional layers by employing summary statistics. \n",
    "\n",
    "![simArch1Layer](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/SimArch1Layer.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ikMRDXRhfaO"
   },
   "outputs": [],
   "source": [
    "#Define the model architecture in keras\n",
    "multi_filter_keras_model=Sequential() \n",
    "multi_filter_keras_model.add(Conv2D(filters=15,kernel_size=(1,10),input_shape=simulation_data.X_train.shape[1::]))\n",
    "multi_filter_keras_model.add(BatchNormalization(axis=-1))\n",
    "multi_filter_keras_model.add(Activation('relu'))\n",
    "multi_filter_keras_model.add(MaxPooling2D(pool_size=(1,35), strides=35))\n",
    "multi_filter_keras_model.add(Flatten())\n",
    "multi_filter_keras_model.add(Dense(1))\n",
    "multi_filter_keras_model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "multi_filter_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JhL10vzhfaQ"
   },
   "outputs": [],
   "source": [
    "multi_filter_keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY_guZFnziif"
   },
   "source": [
    "\"Non-trainable params\" refers to Batch Normalization parameter whose weights don't get updated during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rzKZVoNhfaS"
   },
   "outputs": [],
   "source": [
    "##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "multi_filter_keras_model.compile(optimizer='adam',\n",
    "                               loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xwSZhvVhfaV"
   },
   "source": [
    "We train the model for 150 epochs, with an early stopping criterion -- if the loss on the validation set does not improve for 3 consecutive epochs, the training is halted. In each epoch, the model performs a complete pass over the training data, and updates its parameters to minimize the loss, which quantifies the error in the model predictions. After each epoch, the performance metrics for the model on the validation data were stored. \n",
    "\n",
    "The performance metrics include balanced accuracy, area under the receiver-operating curve ([auROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)), are under the precision-recall curve ([auPRC](https://en.wikipedia.org/wiki/Precision_and_recall)), and recall for multiple false discovery rates  (Recall at [FDR](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjRCE1JJhfaV"
   },
   "outputs": [],
   "source": [
    "from dragonn.callbacks import * \n",
    "#We define a custom callback to print training and validation metrics while training. \n",
    "metrics_callback=MetricsCallback(train_data=(simulation_data.X_train,simulation_data.y_train),\n",
    "                                 validation_data=(simulation_data.X_valid,simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJT2c7XFhfaX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## use the keras fit function to train the model for 150 epochs with early stopping after 3 epochs \n",
    "history_multi_filter=multi_filter_keras_model.fit(x=simulation_data.X_train,\n",
    "                                  y=simulation_data.y_train,\n",
    "                                  batch_size=128,\n",
    "                                  epochs=150,\n",
    "                                  verbose=1,\n",
    "                                  callbacks=[EarlyStopping(patience=3,restore_best_weights=True),\n",
    "                                            metrics_callback],\n",
    "                                  validation_data=(simulation_data.X_valid,\n",
    "                                                   simulation_data.y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSmch4Hghfaa"
   },
   "source": [
    "### Evaluate the model on the held-out test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCCsY5aohfab"
   },
   "outputs": [],
   "source": [
    "## Use the keras predict function to get model predictions on held-out test set. \n",
    "test_predictions=multi_filter_keras_model.predict(simulation_data.X_test)\n",
    "## Generate a ClassificationResult object to print performance metrics on held-out test set \n",
    "print(ClassificationResult(simulation_data.y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSYLNtjjhfaf"
   },
   "source": [
    "### Visualize the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSbvymo7ziiu"
   },
   "outputs": [],
   "source": [
    "#import functions foro visualization of data \n",
    "from dragonn.vis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WSa4OyEhfah"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(history_multi_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0UFcjPMziiy"
   },
   "source": [
    "We can see that the training and validation loss decrease, but the validation loss is somewhat higher than the training loss. This is indicative of over-fitting to the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaBJrS2Qhfal"
   },
   "source": [
    "## Visualize the learned parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWMTRBqJhfal"
   },
   "source": [
    "Next, let's visualize the filter learned in this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u71ItwHBhfan"
   },
   "source": [
    "### Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vwx8sbtuhfan"
   },
   "outputs": [],
   "source": [
    "plot_model_weights(multi_filter_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9Ja44dfhfau"
   },
   "source": [
    "### Convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8v541M5mhfav"
   },
   "outputs": [],
   "source": [
    "W_conv, b_conv = multi_filter_keras_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuBSKMy-hfax"
   },
   "outputs": [],
   "source": [
    "W_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWVP0eEPhfay"
   },
   "outputs": [],
   "source": [
    "b_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRjf1T--hfa0"
   },
   "outputs": [],
   "source": [
    "plot_filters(multi_filter_keras_model, simulation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ys1cqU5whfce",
    "tags": []
   },
   "source": [
    "## For further exploration<a name='9'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRjJ5t00hfce"
   },
   "source": [
    "In this tutorial we explored modeling of homotypic motif density. Other properties of regulatory DNA sequence include\n",
    "![sequence properties 3](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/sequence_properties_3.jpg?raw=1)\n",
    "![sequence properties 4](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/sequence_properties_4.jpg?raw=1)\n",
    "\n",
    "DragoNN provides simulations that formulate learning these patterns into classification problems:\n",
    "![sequence](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/sequence_simulations.png?raw=1)\n",
    "\n",
    "You can view the available simulation functions by running print_available_simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BLPWVdhhfcf"
   },
   "outputs": [],
   "source": [
    "print_available_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v6zqwHX2G3Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PrimerTutorial 1 - Exploring model architectures for a homotypic motif density simulation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
