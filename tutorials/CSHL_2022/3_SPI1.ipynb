{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APNfq3knhfZg"
   },
   "source": [
    "# How to train your DragoNN: \n",
    "## Exploring convolutional neural network (CNN) architectures for simulated genomic data as well as ENCODE TF ChIP-seq datasets. \n",
    "\n",
    "This tutorial will take approximately 2 hours if executed on a GPU. \n",
    "\n",
    "**TODO**: Fix\n",
    "\n",
    "## Outline<a name='outline'>\n",
    "<ol>\n",
    "    <li><a href=#9>Training on real data: SPI1 ChIP-seq and experimental bQTL data</a></li>\n",
    "    <li><a href=#10>Genomewide regression labels for SPI1 TF ChIP-seq</a></li>\n",
    "    <li><a href=#12>Genome-wide regression for SPI1</a></li> \n",
    "    <li><a href=#13>Genome-wide interpretation of true positive predictions in SPI1</a></li>\n",
    "    <li><a href=#14>Applications for SPI1 bQTL dataset</a></li>\n",
    "    <ol>\n",
    "        <li><a href=#a>Read in and annotate SPI1 bQTL dataset</a></li>\n",
    "        <li><a href=#b>Obatin DNN predictions for POST and ALT alleles within the bQTL dataset</a></li>\n",
    "        <li><a href=#c>Compare model predictions on POST and ALT alleles </a></li>\n",
    "        <li><a href=#d>bQTL dataset motif scan with HOCOMOCO SPI1 motif </a></li>\n",
    "        <li><a href=#e>bQTL interpretation summary: deep learning models vs motif scan</a></li>\n",
    "    </ol>\n",
    "    <li><a href=#15>Deep learning models are able to identify low-affinity TF-binding sites missed by motif scanning.</a></li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NixF5bW3hfZg"
   },
   "source": [
    "## How to use this tutorial<a name='1'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "This tutorial utilizes a Google Colaboratory Notebook - an interactive computational enviroment that combines live code, visualizations, and explanatory text. The notebook is organized into a series of cells. \n",
    "\n",
    "The first thing we do is set our Runtime to use Python3 and GPU. \n",
    "\n",
    "![ChangeRuntime](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/ChangeRuntime.png?raw=true)\n",
    "\n",
    "![RuntimeType.png](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/RuntimeType.png?raw=1)\n",
    "\n",
    "Now that we set our Runtime, we can execute the cells in the notebook. You can execute the cells one at a time by clicking inside of them and pressing SHIFT+enter. Alternatively, you can run all the cells by clicking the \"Run All\" button, as demonstrated below. \n",
    "\n",
    "![RunAllColab](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/RunAllCollab.png?raw=1)\n",
    "\n",
    "\n",
    "You can run the next cell by cliking the play button:\n",
    "\n",
    "![RunCellArrow](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/RunCellArrow.png?raw=1)\n",
    "\n",
    "Half of the cells in this tutorial contain code, the other half contain visualizations and explanatory text. Code, visualizations, and text in cells can be modified - you are encouraged to modify the code as you advance through the tutorial. You can inspect the implementation of a function used in a cell by following these steps:\n",
    "\n",
    "![inspecting code](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/inspecting_code.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWLcVFDXzihK"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running locally\n",
    "# import sys\n",
    "# sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wORsai47hfZi"
   },
   "outputs": [],
   "source": [
    "#uncomment the lines below if you are running this tutorial from Google Colab \n",
    "# RESTART NOTEBOOK AFTER RUNNING THIS\n",
    "! pip install git+https://github.com/kundajelab/dragonn.git@cshl\n",
    "! pip install git+https://github.com/kundajelab/shap.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oBUEZ7wMJkq"
   },
   "outputs": [],
   "source": [
    "!pip show tensorflow\n",
    "!pip show dragonn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSaW2fD2hfZk"
   },
   "outputs": [],
   "source": [
    "# Making sure our results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1234)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e2J6BZ-hfZo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load dragonn tutorial utilities \n",
    "from matplotlib import pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wORsai47hfZi"
   },
   "outputs": [],
   "source": [
    "#uncomment the lines below if you are running this tutorial from Google Colab \n",
    "# !pip uninstall albumentations -y \n",
    "# !pip uninstall folium -y \n",
    "# !pip uninstall datascience -y \n",
    "# !pip install dragonn==0.4.1 \n",
    "# !pip uninstall tensorflow \n",
    "# !pip install tensorflow-gpu==1.15\n",
    "# !pip install keras==2.3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2EK0fK1zikX"
   },
   "source": [
    "## Training on \"Real\" Data: SPI1 TF CHiP-seq data from ENCODE  <a name='9'>\n",
    "<a href=#outline>Home</a>\n",
    "We now want to use DragoNN to train and interpret a neural network on real ENCODE TF-ChIP-seq data. We will learn to predict transcription factor binding for the SPI1 transcription factor in the GM12878 cell line (one of the Tier 1 cell lines for the ENCODE project). \n",
    "    \n",
    "Having done this, we want to examine how well the model is able to predict funcational SNP effects on TF binding. We compare predicted variant effect sizes from the regression models against  experimental bQTL data. The bQTL data in this way serves as a \"gold-standard\" validation that in silico mutagenesis on the deep learning inputs leads to correct variant effect size prediction.  We  will use bQTL data  that has been intersected with SPI1 CISBP genome motif annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3g7PZxd7zikX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPI1, optimal IDR thresholded peaks, Myers lab, hg19, GM12878 cell type \n",
    "# https://www.encodeproject.org/experiments/ENCSR000BGQ/\n",
    "!wget -O SPI1.narrowPeak.gz https://www.encodeproject.org/files/ENCFF306SRV/@@download/ENCFF306SRV.bed.gz\n",
    "\n",
    "#Fold change bigWig track for the SPI1 dataset: \n",
    "!wget -O SPI1.pooled.fc.bigWig https://www.encodeproject.org/files/ENCFF793RKX/@@download/ENCFF793RKX.bigWig\n",
    "    \n",
    "## Download \"ambiguous\" peak sets -- these peaks are in the optimal overlap set across replicates, but are not\n",
    "## found to be reproducible at a high confidence (p<0.05) by IDR. We have calculated these in advance and download \n",
    "## them from the tutorial server \n",
    "! wget -O SPI1.ambiguous.gz http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.ambiguous.gz\n",
    "\n",
    "## Download the hg19 chromsizes file (We only use chroms 1 -22, X, Y for training)\n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/hg19.chrom.sizes\n",
    "    \n",
    "## Download the hg19 fasta reference genome (and corresponding .fai index)\n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/hg19.genome.fa.gz\n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/hg19.genome.fa.gz.fai \n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/hg19.genome.fa.gz.gzi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEOROObLzikZ"
   },
   "outputs": [],
   "source": [
    "# Download bQTL experimental data for SPI1 loci \n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.bQTLs.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_ML_dROzikb"
   },
   "source": [
    "## Generating genome-wide regression labels <a name='10'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUpOwDibzikc"
   },
   "source": [
    "We used the *genomewide_labels* function from the  [seqdataloader](https://github.com/kundajelab/seqdataloader) package to generate binned counts for the TF-ChIPseq peaks across the genome. For the sake of time, we will load the pre-generated labels in this tutorial, but the label generation code is included below if you would like to run it on your own datasets. \n",
    "\n",
    "seqdataloader splits the genome into 1kb regions, with a stride of 50. Each 1kb region is centered at a 200 bp bin, with a left flank of 400 bases and a right flank of 400 bases. \n",
    "\n",
    "* In the regression case, the asinh(mean log fold change relative to the input) in the 200 bp bin is computed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYOuQBLdzikd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Download pre-generated genomewide labels \n",
    "## Regression labels \n",
    "#! wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.train.regression.hdf5\n",
    "! wget http://mitra.stanford.edu/kundaje/projects/dragonn/cshl_2022/SPI1.train.regression.1M.hdf5\n",
    "#! wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.valid.regression.hdf5\n",
    "! wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.valid.regression.1M.hdf5\n",
    "#! wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.test.regression.hdf5\n",
    "! wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.test.regression.1M.hdf5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTMjGoVSzikf"
   },
   "source": [
    "If you are interested in how the labels were generated, you can run the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZVvv1MZzikf",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from seqdataloader import * \n",
    "# from seqdataloader.labelgen import genomewide_labels\n",
    "\n",
    "## seqdataloader accepts an input file, which we call SPI1.tasks.tsv, with task names in column 1, corresponding\n",
    "## peak files in column 2, and the signal track in column 3. In this tutorial, the task file will have a single task entry for the SPI1 TF CHiP-seq\n",
    "# with open(\"SPI1.task.tsv\",'w') as f: \n",
    "#     f.write(\"task\\tnarrowPeak\\tbigwig\\tambig\\n\")\n",
    "#     f.write(\"SPI1\\tSPI1.narrowPeak.gz\\tSPI1.pooled.fc.bigWig\\tSPI1.ambiguous.gz\\n\")\n",
    "#f.close() \n",
    "#!cat SPI1.task.tsv\n",
    "\n",
    "## Generate regression labels genome-wide \n",
    "\n",
    "##1) Training set: all chromosomes with the exception of 1,2, and 19 in our training set \n",
    "\n",
    "# train_set_params={\n",
    "#    'task_list':\"SPI1.task.tsv\",\n",
    "#    'outf':\"SPI1.train.regression.hdf5\",\n",
    "#    'output_type':'hdf5',\n",
    "#    'chrom_sizes':'hg19.chrom.sizes',\n",
    "#    'chroms_to_exclude':['chr1','chr2','chr19','chrY'],\n",
    "#    'bin_stride':50,\n",
    "#    'left_flank':400,\n",
    "#    'right_flank':400,\n",
    "#    'bin_size':200,\n",
    "#    'threads':4,\n",
    "#    'subthreads':4,\n",
    "#    'allow_ambiguous':True,\n",
    "#    'labeling_approach':'all_genome_bins_regression'\n",
    "#    }\n",
    "# genomewide_labels(train_set_params)\n",
    "\n",
    "##2) Validation set: Chromosome 1\n",
    "#valid_set_params={'task_list':\"SPI1.task.tsv\",\n",
    "#    'outf':\"SPI1.valid.regression.hdf5\",\n",
    "#    'output_type':'hdf5',\n",
    "#    'chrom_sizes':'hg19.chrom.sizes',\n",
    "#    'chroms_to_keep':'chr1',\n",
    "#    'bin_stride':50,\n",
    "#    'left_flank':400,\n",
    "#    'right_flank':400,\n",
    "#    'bin_size':200,\n",
    "#    'threads':1,\n",
    "#    'subthreads':4,\n",
    "#    'allow_ambiguous':True,\n",
    "#    'labeling_approach':'all_genome_bins_regression'\n",
    "#    }\n",
    "#genomewide_labels(valid_set_params)\n",
    "\n",
    "##3) Test set: Chromosomes 2, 19 \n",
    "#test_set_params={\n",
    "#    'task_list':\"SPI1.task.tsv\",\n",
    "#    'outf':\"SPI1.test.regression.hdf5\",\n",
    "#    'output_type':'hdf5',\n",
    "#    'chrom_sizes':'hg19.chrom.sizes',\n",
    "#    'chroms_to_keep':['chr2','chr19'],\n",
    "#    'bin_stride':50,\n",
    "#    'left_flank':400,\n",
    "#    'right_flank':400,\n",
    "#    'bin_size':200,\n",
    "#    'threads':2,\n",
    "#    'subthreads':4,\n",
    "#    'allow_ambiguous':True,\n",
    "#    'labeling_approach':'all_genome_bins_regression'\n",
    "#    }\n",
    "#genomewide_labels(test_set_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGtvoGGnziki"
   },
   "source": [
    "Let's examine the label files that were generated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdc--xdPziki"
   },
   "outputs": [],
   "source": [
    "#The code generates bed file outputs with asinh(mean log fold change relative to the input) \n",
    "# in the central 200 bp bin \n",
    "import pandas as pd\n",
    "pd.read_hdf(\"SPI1.train.regression.1M.hdf5\",start=0,end=1000, key='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFps3yHa2G0x"
   },
   "source": [
    "We will now train genome-wide regression models: \n",
    "![GenomeWideModel](https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/GenomeWideModel.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CabIdVIozikj",
    "tags": []
   },
   "source": [
    "## Genome-wide regression model <a name='11'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5kRuWJMzikk"
   },
   "outputs": [],
   "source": [
    "# To prepare for model training, we import the necessary functions and submodules from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Reshape, Dense, Activation, Flatten,Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HUkW7Tvzik5"
   },
   "outputs": [],
   "source": [
    "from dragonn.runtime_metrics import precision, recall, specificity, fpr, fnr, fdr, f1\n",
    "from dragonn.custom_losses import ambig_mean_squared_error\n",
    "\n",
    "def initialize_regression_model(ntasks=1):\n",
    "    #Define the model architecture in keras (regularized, 3-layer convolution model followed by 1 dense layer)\n",
    "    model=Sequential() \n",
    "    \n",
    "    model.add(Conv2D(filters=50,kernel_size=(1,15),padding=\"same\", input_shape=(1,1000,4)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=50,kernel_size=(1,15),padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=50,kernel_size=(1,13),padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(1,40)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50))\n",
    "    # model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(ntasks))\n",
    "\n",
    "    loss=ambig_mean_squared_error\n",
    "    ##compile the model, specifying the Adam optimizer, and binary cross-entropy loss. \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhv9esVjziko"
   },
   "source": [
    "We create generators for the training and validation data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsZcWvp1zik6"
   },
   "source": [
    "We upsample bins with signal greater than 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the generators, upsample positives to ensure they constitute 30% of each batch \n",
    "from dragonn.generators import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xBebnJHzik6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the generators, we upsample positives to make 50% of each batch.\n",
    "spi1_train_regression_gen=DataGenerator(\"SPI1.train.regression.1M.hdf5\",\"hg19.genome.fa.gz\", upsample_ratio=0.5, upsample_thresh=.1)\n",
    "spi1_valid_regression_gen=DataGenerator(\"SPI1.valid.regression.1M.hdf5\",\"hg19.genome.fa.gz\",\n",
    "                                        upsample=False,\n",
    "                                        add_revcomp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9jZ-5UGzikp"
   },
   "source": [
    "For the sake of time, we will train the model for 10 epochs, using 100 steps per epoch in training and validation.\n",
    "**steps_per_epoch** indicates the number of batches that constitute a single epoch (recall that an epoch constitutes a full forward and backward pass of the dataset through the model before weights are updated). In practice, we often don't need to pass the full dataset through the model to constitute an epoch, especially when the dataset is very large. We can specify the epoch size with the **steps_per_epoch** argument. \n",
    "\n",
    "Use larger values when training an actual model -- a recommended epoch size is 100000 samples for training and 50000 for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZretQD22zik7",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train the SPI1 regression model \n",
    "spi1_regression_model=initialize_regression_model()\n",
    "\n",
    "## use the keras fit_generator function to train the model with early stopping after 3 epochs \n",
    "history_regression=spi1_regression_model.fit_generator(spi1_train_regression_gen,\n",
    "                                                 validation_data=spi1_valid_regression_gen,\n",
    "                                                 steps_per_epoch=1000,\n",
    "                                                 validation_steps=200,\n",
    "                                                 epochs=20,\n",
    "                                                 verbose=1,\n",
    "                                                 use_multiprocessing=True,\n",
    "                                                 workers=20,\n",
    "                                                 max_queue_size=100,\n",
    "                                                 callbacks=[EarlyStopping(patience=5,restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions for visualization of data \n",
    "from dragonn.vis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncXVdBUfzikr"
   },
   "outputs": [],
   "source": [
    "## Plot the learning curves for SPI1  \n",
    "plot_learning_curve(history_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGmg8Q7K2G03"
   },
   "source": [
    "The training loss curve decreases gradually over the 7 epochs of training, while the validation loss drops sharply on the first epoch and then remains relatively flat. A possible explanation is that the training set is upsampled to include 10% positives in each batch, while the validation set is not upsampled and therefor has approximately 2% positives in each batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDpmWYfgzik-"
   },
   "outputs": [],
   "source": [
    "#We load a regression model that has been trained on epochs of size 100000 until the early stopping criterion\n",
    "# was met. \n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/cshl_2022/SPI1.regression.model.hdf5\n",
    "\n",
    "from keras.models import load_model\n",
    "from dragonn.custom_losses import * \n",
    "from dragonn.metrics import * \n",
    "custom_objects={\"recall\":recall,\n",
    "                \"sensitivity\":recall,\n",
    "                \"specificity\":specificity,\n",
    "                \"fpr\":fpr,\n",
    "                \"fnr\":fnr,\n",
    "                \"fdr\":fdr,\n",
    "                \"precision\":precision,\n",
    "                \"f1\":f1,\n",
    "                \"ambig_mean_squared_error\":ambig_mean_squared_error}\n",
    "spi1_regression_model=load_model(\"SPI1.regression.model.hdf5\",custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kbruUiOzikt"
   },
   "source": [
    "We now measure how well the model performed by calculating performance metrics on the test splits across the whole genome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UG2lQCIzzik_"
   },
   "outputs": [],
   "source": [
    "#Get predictions on the test set \n",
    "spi1_test_regression_gen=DataGenerator(\"SPI1.test.regression.1M.hdf5\",\n",
    "                                       \"hg19.genome.fa.gz\",\n",
    "                                         upsample=False,\n",
    "                                         add_revcomp=False,\n",
    "                                         batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9BQKMMfzilA",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spi1_test_regression_predictions=spi1_regression_model.predict_generator(spi1_test_regression_gen,\n",
    "                                                                         max_queue_size=5000,\n",
    "                                                                         workers=20,\n",
    "                                                                         use_multiprocessing=True,\n",
    "                                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyWSQESizilC"
   },
   "outputs": [],
   "source": [
    "spi1_test_regression_labels=spi1_test_regression_gen.data\n",
    "spi1_test_regression_predictions=np.expand_dims(spi1_test_regression_predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJkhtUlOzikx"
   },
   "outputs": [],
   "source": [
    "#remove nans, as they corresponnd to ambiguous values \n",
    "nan_indices=np.isnan(spi1_test_regression_labels.values.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIF9E7UVzilC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove nans, as they correspond to ambiguous values \n",
    "spi1_test_regression_labels=spi1_test_regression_labels[~nan_indices]\n",
    "spi1_test_regression_predictions=spi1_test_regression_predictions[~nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88p0zrHKzilD"
   },
   "outputs": [],
   "source": [
    "#Calculate spearman and pearson correlation between truth labels and predictions \n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "corr_pearson=pearsonr(spi1_test_regression_labels['SPI1'],spi1_test_regression_predictions.ravel())\n",
    "corr_spearman=spearmanr(spi1_test_regression_labels['SPI1'],spi1_test_regression_predictions.ravel())\n",
    "print(\"Pearson correlation on test set:\"+str(corr_pearson))\n",
    "print(\"Spearman correlation on test set:\"+str(corr_spearman))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9AHLmQ5zilH",
    "tags": []
   },
   "source": [
    "## Genome-wide interpretation of true positive predictions in SPI1 <a name='13'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEwolYHNzilP"
   },
   "source": [
    "### Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaGQcgJgzilP"
   },
   "outputs": [],
   "source": [
    "#Sanity-check that the model is learning the SPI1 motif by running DeepLIFT on True Positives with high confidence \n",
    "#get the true positive predictions \n",
    "true_pos_regression=spi1_test_regression_labels[(spi1_test_regression_labels.values*spi1_test_regression_predictions)>4]\n",
    "true_pos_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaRNAEkpzilR"
   },
   "outputs": [],
   "source": [
    "from dragonn.utils import one_hot_from_bed\n",
    "\n",
    "interpretation_input_regression_spi1=one_hot_from_bed([i for i in true_pos_regression.index],\"hg19.genome.fa.gz\")\n",
    "interpretation_input_regression_spi1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqAZHYvtzilS"
   },
   "outputs": [],
   "source": [
    "regression_positive_example= np.expand_dims(interpretation_input_regression_spi1[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HB3Eqw4pzilS"
   },
   "outputs": [],
   "source": [
    "#get the deeplift scoring function for regression\n",
    "# deeplift_score_func_regression=get_deeplift_scoring_function(\"SPI1.regression.model.hdf5\",target_layer_idx=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yMEBuJAzilT"
   },
   "outputs": [],
   "source": [
    "from dragonn.interpret import * \n",
    "\n",
    "regression_interpretations=multi_method_interpret(spi1_regression_model,\n",
    "                                           regression_positive_example,\n",
    "                                           0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADwBkACwzilX"
   },
   "outputs": [],
   "source": [
    "plot_all_interpretations([regression_interpretations],regression_positive_example,xlim=(500,600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAewPLWlzilP"
   },
   "source": [
    "If we query the sequence of the observed motif in the [TomTom](http://meme-suite.org/tools/tomtom) software from the MEME suite, we should find  that the motif is a good match for SPIB. \n",
    "An example you might observe is below: \n",
    "<img src=\"https://github.com/kundajelab/dragonn/blob/master/tutorials/tutorial_images/SPI1.Tut4.png?raw=1\" alt=\"SPI12TomTom\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1wFdF75zilY"
   },
   "source": [
    "## SPI1 Binding Quantitative Trait Loci (bQTL) Data <a name='14'>\n",
    "    \n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "A study by Fraser et al (https://www.cell.com/fulltext/S0092-8674(16)30339-7) identified several thousand cis-acting bQTL's that affect the binding of SPI1 transcription factors in humans. We examine how effective our models are at recognizing these bQTLs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQXpNOMgzilZ"
   },
   "source": [
    "### Read in and annotate the bQTL dataset <a name='a'>\n",
    "<a href=#outline>Home</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0465EF4zilZ"
   },
   "outputs": [],
   "source": [
    "## Download the bQTL dataset \n",
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.bQTLs.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfXlmDRJzild"
   },
   "outputs": [],
   "source": [
    "#Read in the bQTL dataframe\n",
    "bqtls=pd.read_csv(\"SPI1.bQTLs.txt.gz\",header=0,sep='\\t')\n",
    "bqtls.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEmIb7UFzile"
   },
   "outputs": [],
   "source": [
    "#Calculate the number of bQTL's\n",
    "print(bqtls.shape)\n",
    "n_bqtls=bqtls.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvR8jl19zilh"
   },
   "outputs": [],
   "source": [
    "#sort the bqtl's by p-value \n",
    "bqtls=bqtls.sort_values(by=['pvalue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOp7V87Tzili"
   },
   "source": [
    "We now annotate the bQTL's with the false discovery rate, the mean fold change bigWig signal in the bQTL region, and the logratio fo the post-CHIP frequency relative to the pre-CHIP frequency. Some of these operations are time-consuming, particularly the calculation of the mean fold change bigWig signal. Hence,we have pre-run them. If you would like to execute these operations, uncomment the code cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALWPULyUzili"
   },
   "outputs": [],
   "source": [
    "!wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.bQTLs.additional.metrics.txt.gz\n",
    "bqtls=pd.read_csv(\"SPI1.bQTLs.additional.metrics.txt.gz\",header=0,sep='\\t')\n",
    "bqtls.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZZeHn2Qzilj"
   },
   "outputs": [],
   "source": [
    "##Calculate the Benjamini-Hochberg FDR \n",
    "#bqtls['FDR']=1.0\n",
    "#for index,row in bqtls.iterrows(): \n",
    "#    row['FDR']=min(row['FDR'],row['pvalue']*n_bqtls/(index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDmzVJWDzilk"
   },
   "outputs": [],
   "source": [
    "## Calculate logratio of the Post-CHIP frequency to the pre-CHIP frequency\n",
    "#bqtls['logratio']=np.log((bqtls['POSTfreq']+.01)/(bqtls['prechipfreq']+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA23VgW2zill"
   },
   "outputs": [],
   "source": [
    "## IMPORTANT! Convert the bQTL coordinates from 1-indexing to 0-indexing\n",
    "#bqtls['start']=bqtls['position']-1\n",
    "#bqtls['end']=bqtls['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZumXrJSzill"
   },
   "outputs": [],
   "source": [
    "## Calculate the mean fold change bigWig signal within the 200 bp region \n",
    "## centered on the bQTL\n",
    "\n",
    "##initialize the field within the Pandas dataframe with default value of 0\n",
    "#bqtls['mean_chipseq_fc']=0\n",
    "\n",
    "##use the pyBigWig library to calculate the mean fold change bigWig signal \n",
    "##within the 200 bp region centered at the bQTL \n",
    "#import pyBigWig \n",
    "#bigwig_fh = pyBigWig.open(\"SPI1.pooled.fc.bigWig\")\n",
    "#for index,row in bqtls.iterrows():\n",
    "#    values = bigwig_fh.values(row['Chr'],\n",
    "#                              row['end']-100,\n",
    "#                              row['end']+100,\n",
    "#                              numpy=True)\n",
    "#    row['mean_chipseq_fc'] = np.mean(values)\n",
    "#    if (index%1000 == 0):\n",
    "#        print(\"Done\",index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNHTAvpEziln"
   },
   "outputs": [],
   "source": [
    "##Let's save the augmented bQTL data frame so we can resume from \n",
    "## this point in the analysis more easily. \n",
    "#bqtls.to_csv(\"SPI1.bQTLs.additional.metrics.txt.gz\",\n",
    "#            sep='\\t',\n",
    "#            header=True,\n",
    "#            index=False,\n",
    "#            compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWay4G5azilo"
   },
   "source": [
    "### DNN predictions for Post and Alt alleles within the bQTL dataset  <a name='b'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eOKuuG2zilo"
   },
   "source": [
    "We would like to obtain  predictions for the reference and alternate alleles at each bQTL. Because we will visualize the difference in predictions for the reference and alternate bQTL alleles, we will operate in logit space -- the layer in the model whose output feeds into the final sigmoid layer. We do this because calculating the logratio of model predictions in logit space is more correct than subtracting probabilities from the model's final sigmoid output layer. \n",
    "\n",
    "Consequently, we obtain the predictions of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkTEeCV-zilr"
   },
   "outputs": [],
   "source": [
    "# get model predictions for bQTLs \n",
    "from dragonn.generators import * \n",
    "bqtl_post_gen=BQTLGenerator(\"SPI1.bQTLs.txt.gz\",\"hg19.genome.fa.gz\",\"POSTallele\")\n",
    "bqtl_alt_gen=BQTLGenerator(\"SPI1.bQTLs.txt.gz\",\"hg19.genome.fa.gz\",\"ALTallele\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngU4Zy3ezilv"
   },
   "outputs": [],
   "source": [
    "bqtl_post_regression_predictions=spi1_regression_model.predict_generator(bqtl_post_gen,\n",
    "                                                                          max_queue_size=5000,\n",
    "                                                                          workers=40,\n",
    "                                                                          use_multiprocessing=True,\n",
    "                                                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8fxMDKBzily"
   },
   "outputs": [],
   "source": [
    "bqtl_alt_regression_predictions=spi1_regression_model.predict_generator(bqtl_alt_gen,\n",
    "                                                                          max_queue_size=5000,\n",
    "                                                                          workers=40,\n",
    "                                                                          use_multiprocessing=True,\n",
    "                                                                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRRcztgFzilz"
   },
   "source": [
    "Let's augment the bQTL dataframe with the model predictions. Let's summarize the predictions we have generated on the bQTL dataset: \n",
    "\n",
    "* Regression model predictions for the POST allele \n",
    "* Regression model predictions for the ALT allele \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVi1GZQJzilz"
   },
   "outputs": [],
   "source": [
    "bqtls['post_regression_predictions']=bqtl_post_regression_predictions\n",
    "bqtls['alt_regression_predictions']=bqtl_alt_regression_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9XQDDdkzil1"
   },
   "source": [
    "## Compare model predictions on POST and ALT alleles  <a name='c'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "\n",
    "We now assess whether the model predictions of accessibility change for significant bQTL's when the reference allele is replaced with the alternate allele in the input sequence. We also compare the distribution of reference vs alternate predictions for the set of significant bQTLS to the corresponding distribution for the set of non-significant bQTLs. \n",
    "\n",
    "First, we must select comparable subsets of non-significant and significant bQTLs from the bQTL dataset. For our purposes, the sets are comparable if they have similar distributions of accessibility predictions, where predictions are defined as the max of the reference and alternate allele predictions. To ensure that we are comparing such \"matched\" subsets, we perform the following steps:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vL-VeUSzil1"
   },
   "outputs": [],
   "source": [
    "#We define a temporary field to store the maximum of the \n",
    "# regression predictions for the alternate and reference alleles \n",
    "bqtls['max_regression_predictions']=bqtls[['post_regression_predictions',\n",
    "                                          'alt_regression_predictions']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOJTr6P7zil3"
   },
   "outputs": [],
   "source": [
    "significant_bqtls=bqtls[bqtls['pvalue']<=5e-5]\n",
    "non_significant_bqtls=bqtls[bqtls['pvalue']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Hk5KbgMzil3"
   },
   "outputs": [],
   "source": [
    "significant_bqtls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIBsz5fzzil5"
   },
   "outputs": [],
   "source": [
    "non_significant_bqtls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy3F7rBWzil6"
   },
   "source": [
    "We define a helper function to sample bQTLS from the bQTL dataset to match another subset of bQTLS according to a user-specified attr_name. This function will allow us to compare the accessibility predictions for significant bQTLS with the non-significant bQTLS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tx8w8VBHzil6"
   },
   "outputs": [],
   "source": [
    "from plotnine import * \n",
    "def plot_distribution(bqtls_to_match,matched_sampled_bqtls,attr_name):\n",
    "    toplot=pd.DataFrame({\"bqtls_to_match\":bqtls_to_match[attr_name],\n",
    "                        \"matched_sampled_bqtls\":matched_sampled_bqtls[attr_name]})\n",
    "    toplot=toplot.melt()\n",
    "    print((ggplot(toplot,aes(x=\"value\",group=\"variable\",color=\"variable\",fill=\"variable\"))\n",
    "     +geom_density(alpha=0.3)\n",
    "     +theme_bw()\n",
    "     +xlab(attr_name)\n",
    "     +ylab(\"Density\")))\n",
    "\n",
    "    print((ggplot(bqtls_to_match,aes(x=attr_name))\n",
    "     +geom_density(alpha=0.3)\n",
    "     +theme_bw()\n",
    "     +xlab(attr_name)\n",
    "     +ylab(\"Density\")\n",
    "     +ggtitle(\"bqtls_to_match\")))\n",
    "\n",
    "    print((ggplot(matched_sampled_bqtls,aes(x=attr_name))\n",
    "     +geom_density(alpha=0.3)\n",
    "     +theme_bw()\n",
    "     +xlab(attr_name)\n",
    "     +ylab(\"Density\")\n",
    "     +ggtitle(\"matched_sampled_bqtls\")))\n",
    "\n",
    "\n",
    "\n",
    "def sample_matched_bqtls(bqtls_to_match, bqtls_to_sample, attr_name):\n",
    "    #sort bqtls_to_sample by attr_name\n",
    "    sorted_bqtls_to_sample=bqtls_to_sample.sort_values(by=[attr_name])\n",
    "    sorted_bqtls_to_sample_vals = sorted_bqtls_to_sample[attr_name]\n",
    "    \n",
    "    bqtls_to_match_vals = bqtls_to_match[attr_name]\n",
    "    \n",
    "    #find indices in the bqtls_to_match_vals Series that are close in value to corresponding entries \n",
    "    # from sorted_bqtls_to_sample_vals\n",
    "    searchsorted_indices = np.searchsorted(a=np.array(sorted_bqtls_to_sample_vals), \n",
    "                                           v=np.array(bqtls_to_match_vals))\n",
    "    \n",
    "    matched_sampled_bqtls_indices = set()\n",
    "    \n",
    "    for idx in searchsorted_indices:\n",
    "        #shift the index until you find one that isn't taken\n",
    "        shift = 1\n",
    "        while (idx in matched_sampled_bqtls_indices or idx==len(sorted_bqtls_to_sample)):\n",
    "            if idx == len(sorted_bqtls_to_sample):\n",
    "                shift = -1\n",
    "            idx += shift\n",
    "        if (idx < 0 or idx > len(sorted_bqtls_to_sample)):\n",
    "            print(idx)\n",
    "        matched_sampled_bqtls_indices.add(idx)\n",
    "    \n",
    "    matched_sampled_bqtls = sorted_bqtls_to_sample.iloc[list(matched_sampled_bqtls_indices)]\n",
    "    \n",
    "    plot_distribution(bqtls_to_match,matched_sampled_bqtls,attr_name)\n",
    "        \n",
    "    return matched_sampled_bqtls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dawg4IPWzil7"
   },
   "source": [
    "We now utilize the \"sample_matched_bqtls\" helper function to select matched subsets of significant and non-significant bQTLs by model prediction values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LggQaDnczil7"
   },
   "outputs": [],
   "source": [
    "matched_bqtls_maxaltpost = sample_matched_bqtls(bqtls_to_match=significant_bqtls,\n",
    "                                                     bqtls_to_sample=non_significant_bqtls,\n",
    "                                                     attr_name=\"max_regression_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnkTPHT3zil8"
   },
   "source": [
    "We have now verified that the distribution of max(alt allele prediction, ref allele predictions) for the significant bQTL subset matches the corresponding distribution for the non-significant bQTL subset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZdJymUuzil8"
   },
   "source": [
    "Our next step is to generate a scatterplot examining the model predictions for reference vs alternate alleles within the matched significant and non-significant subsets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIKNKAh0zil8"
   },
   "outputs": [],
   "source": [
    "#concatenate the subset of significant bQTL's and the matched subset of non-significant bQTL's for visualization on the \n",
    "# same plotting axes \n",
    "significant_bqtls['Significant_bQTL']=True\n",
    "matched_bqtls_maxaltpost['Significant_bQTL']=False \n",
    "to_score_bqtls=pd.concat([significant_bqtls,matched_bqtls_maxaltpost],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCHQZZhyzil9"
   },
   "outputs": [],
   "source": [
    "#concatenate the subset of significant bQTL's and the matched subset of non-significant bQTL's for visualization on the \n",
    "# same plotting axes \n",
    "significant_bqtls['Significant_bQTL']=True\n",
    "matched_bqtls_maxaltpost['Significant_bQTL']=False \n",
    "to_score_bqtls=pd.concat([significant_bqtls,matched_bqtls_maxaltpost],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zctOjnDfzil_"
   },
   "outputs": [],
   "source": [
    "significant_to_score_bqtls=to_score_bqtls[to_score_bqtls['Significant_bQTL']==True]\n",
    "insignificant_to_score_bqtls=to_score_bqtls[to_score_bqtls['Significant_bQTL']==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFxrs2qIzil_"
   },
   "outputs": [],
   "source": [
    "#use the plotnine plotting library to generate a scatterplot of  predictions \n",
    "# for the POST and ALT alleles within the significant and matched non-significant bQTL subsets. \n",
    "\n",
    "\n",
    "print((ggplot(significant_to_score_bqtls,aes(x=\"post_regression_predictions\",\n",
    "                y=\"alt_regression_predictions\"))\n",
    "             +geom_point(alpha=0.3,color=\"#0000FF\")\n",
    "             +xlab(\"POST regression predictions\")\n",
    "             +ylab(\"ALT regression predictions\")\n",
    "             +theme_bw()\n",
    "             +ggtitle(\"Significant bQTLS\")))\n",
    "\n",
    "print((ggplot(insignificant_to_score_bqtls,aes(x=\"post_regression_predictions\",\n",
    "                y=\"alt_regression_predictions\"))\n",
    "             +geom_point(alpha=0.3,color=\"#FF0000\")\n",
    "             +xlab(\"POST regression predictions\")\n",
    "             +ylab(\"ALT regression predictions\")\n",
    "             +theme_bw()\n",
    "             +ggtitle(\"Non-Significant bQTLS\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H14oQ8wSzimA"
   },
   "source": [
    "As expected, we observe a much higher fraction of significant bQTL's deviating from the diagonal of the plot relative to the non-significant bQTL's. This makes sense -- if a bQTL lies along the diagonal, then the model prediction for the POST allele is very close to the prediction for the ALT allele (i.e. the SNP does not have a strong effect on prediction of accessibility). However, when a bQTL lies far from the diagonal, the model predicts a different probability of chromatin accessibility for the POST and ALT alleles -- i.e. the SNP is disrupting TF binding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5gUjBXvzimA"
   },
   "source": [
    "## bQTL dataset motif scan with HOCOMOCO SPI1 motif  <a name='d'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg4kQ--7zimB"
   },
   "source": [
    "Our next step is to annotate the to-score bQTLs with the fasta sequence around them and do motif scoring to determine whether the SPI1 motif is driving the change in model predictions for the reference and altenate alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4HBTlvqzimB"
   },
   "outputs": [],
   "source": [
    "#We save the \"to_score\" bQTL subset to an output file so we can reproduce this analysis in the future starting from the \n",
    "# motif scoring step. \n",
    "to_score_bqtls.to_csv(\"SPI1.bQTLs.toScore.txt.gz\",\n",
    "                      sep='\\t',\n",
    "                      index=False,\n",
    "                      compression=\"gzip\")\n",
    "num_to_score=to_score_bqtls.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWFPP4oYzimC"
   },
   "outputs": [],
   "source": [
    "#We use a flank size of 10 on either side of the bQTL \n",
    "flank_size=10\n",
    "\n",
    "#Once again, we initialize our POST and ALT generators for the bQTL dataset, focusing only on the significant bQTLs and \n",
    "# our matched non-significant subset. \n",
    "#We use a hack where we set the batch size equal to the number of bQTL's to be scored so we get the one-hot-encoding \n",
    "#for all bQTL's simultaneously in one batch \n",
    "bqtl_post_gen=BQTLGenerator(\"SPI1.bQTLs.toScore.txt.gz\",\n",
    "                            \"hg19.genome.fa.gz\",\n",
    "                            \"POSTallele\",\n",
    "                            flank_size=flank_size,\n",
    "                            batch_size=num_to_score)\n",
    "bqtl_alt_gen=BQTLGenerator(\"SPI1.bQTLs.toScore.txt.gz\",\n",
    "                           \"hg19.genome.fa.gz\",\n",
    "                           \"ALTallele\",\n",
    "                           flank_size=flank_size,\n",
    "                           batch_size=num_to_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhyXHOudzimE"
   },
   "source": [
    "We now load the SPI1 count matrix from the [HOCOMOCO](http://hocomoco11.autosome.ru/motif/SPI1_HUMAN.H11MO.0.A) database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSdnXXZFzimF"
   },
   "outputs": [],
   "source": [
    "! [[ -e SPI1.pcm ]] || curl https://hocomoco11.autosome.org/final_bundle/hocomoco11/full/HUMAN/mono/pcm/SPI1_HUMAN.H11MO.0.A.pcm > SPI1.pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLwKiO4AzimG"
   },
   "outputs": [],
   "source": [
    "! cat SPI1.pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4UTGZEOzimH"
   },
   "outputs": [],
   "source": [
    "spi1_pcm = np.array([\n",
    "                [float(x) for x in row.rstrip().split(\"\\t\")]\n",
    "                for (i,row) in enumerate(open(\"SPI1.pcm\")) if i > 0]).transpose((1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_5Z3JcnzimI"
   },
   "outputs": [],
   "source": [
    "spi1_pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erAS_hxgzimJ"
   },
   "outputs": [],
   "source": [
    "#add a pseudocount for motif normalization \n",
    "pseudocount=10e-4\n",
    "spi1_pcm+=pseudocount\n",
    "spi1_pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPCBdAVhzimK"
   },
   "outputs": [],
   "source": [
    "#calculate the frequency matrix from the count matrix \n",
    "#print row-sums \n",
    "np.sum(spi1_pcm,axis=0)\n",
    "#normalize by row-sums \n",
    "spi1_pfm=spi1_pcm/np.sum(spi1_pcm,axis=0)\n",
    "#sanity-check that the row-sums for the position frequency matrix (pfm) are 1 \n",
    "np.sum(spi1_pfm,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM-oPb0HzimL"
   },
   "outputs": [],
   "source": [
    "#plot the pwm \n",
    "plot_bases(spi1_pfm.transpose(),figsize=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqaxLKQczimM"
   },
   "outputs": [],
   "source": [
    "#plot the reverse complement of the pwm \n",
    "from dragonn.utils import reverse_complement\n",
    "plot_bases(reverse_complement(spi1_pfm.transpose()),figsize=(6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f67WWPnazimN"
   },
   "source": [
    "Note that the high confidence true positive SPI1 peaks we interpreted have deepLIFT score profiles resembling the \n",
    "reverse complement SPI1B motif. \n",
    "\n",
    "For each SNP in our bQTL scoring subset, we compute the maximum motif scan score along the 20 bp flanking the reference allele and the alternate allele. In this motif scan, we consider both the motif logo and the reverse complement of the motif logo. We then calculate the difference in the maximum motif score for the alternate allele and the reference allele. These scores should be higher for the significant subset of bQTLs compared to the non-significant subset of bQTLs. We verify that this is indeed the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPjzguJ6zimN"
   },
   "source": [
    "In peforming the motif scan, we normalize relative to the gc content of the SPI1 peaks in our dataset. Let's calculate this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teEJzCthzimN"
   },
   "outputs": [],
   "source": [
    "# We should have the SPI1.narrowPeak.gz file already downloaded, but just in case  here is the link to download \n",
    "# it again. \n",
    "#!wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.narrowPeak.gz\n",
    "from dragonn.utils import allele_freqs_from_bed, get_motif_scores\n",
    "spi1_peak_freqs=allele_freqs_from_bed(\"SPI1.narrowPeak.gz\",\"hg19.genome.fa.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQWz-YpjzimO"
   },
   "outputs": [],
   "source": [
    "# a, c, g, t frequqencies \n",
    "print(spi1_peak_freqs)\n",
    "GC_fraction=spi1_peak_freqs[1]+spi1_peak_freqs[2]\n",
    "print(GC_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGZYyGe9zimP"
   },
   "outputs": [],
   "source": [
    "#Get the maximum sequence SPI1B scan scores for the reference allele \n",
    "to_score_bqtls['scan_post_scores']=np.max(\n",
    "    get_motif_scores(\n",
    "        bqtl_post_gen[0],\n",
    "        [\"SPI1B\"],\n",
    "        GC_fraction=GC_fraction,\n",
    "        pfm=spi1_pfm,\n",
    "        include_rc=True)\n",
    "    ,axis=2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngNt3ExkzimQ"
   },
   "outputs": [],
   "source": [
    "#Get the maximum sequence SPI1B scan scores for the alternate alelle \n",
    "to_score_bqtls['scan_alt_scores']=np.max(\n",
    "    get_motif_scores(\n",
    "        bqtl_alt_gen[0],\n",
    "        [\"SPI1B\"],\n",
    "        GC_fraction=GC_fraction,\n",
    "        pfm=spi1_pfm, \n",
    "        include_rc=True)\n",
    "    ,axis=2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA1bxJ1NzimQ"
   },
   "outputs": [],
   "source": [
    "#Compute the scan score delta for the reference allele - alternate allele \n",
    "to_score_bqtls['scan_delta']=to_score_bqtls['scan_post_scores']-to_score_bqtls['scan_alt_scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGMD3nl9zimR"
   },
   "source": [
    "We summarize our findings below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJb4iSIvzimR"
   },
   "source": [
    "### bQTL interpretation summary: deep learning models vs motif scan  <a name='e'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_0TkK6-zimR"
   },
   "source": [
    "#### Motif scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbVLxEAqzimR"
   },
   "outputs": [],
   "source": [
    "#We plot the motif scan scores for the POST and ALT alleles: \n",
    "significant_to_score_bqtls=to_score_bqtls[to_score_bqtls['Significant_bQTL']==True]\n",
    "insignificant_to_score_bqtls=to_score_bqtls[to_score_bqtls['Significant_bQTL']==False]\n",
    "\n",
    "print((ggplot(significant_to_score_bqtls,aes(x=\"scan_post_scores\",\n",
    "                y=\"scan_alt_scores\"))\n",
    "             +geom_point(alpha=0.3,color=\"#0000FF\")\n",
    "             +xlab(\"POST allele motif scan score for SPI1B\")\n",
    "             +ylab(\"ALT allele motif scan score for SPI1B\")\n",
    "             +ggtitle(\"Significant bQTLs\")\n",
    "             +theme_bw()))\n",
    "print((ggplot(insignificant_to_score_bqtls,aes(x=\"scan_post_scores\",\n",
    "                y=\"scan_alt_scores\"))\n",
    "             +geom_point(alpha=0.3,color=\"#FF0000\")\n",
    "             +xlab(\"POST allele motif scan score for SPI1B\")\n",
    "             +ylab(\"ALT allele motif scan score for SPI1B\")\n",
    "             +ggtitle(\"Non-Significant bQTLs\")\n",
    "             +theme_bw()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grFeMnarzimS"
   },
   "source": [
    "Recall that we defined the bQTL logratio as the  logratio of the Post-CHIP frequency to the pre-CHIP frequency. Plotting the bQTL logratio vs the delta of the PWM scan score gives: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExuBPgY0zimT"
   },
   "outputs": [],
   "source": [
    "print((ggplot(to_score_bqtls,aes(x=\"logratio\",\n",
    "                y=\"scan_delta\",\n",
    "                group=\"Significant_bQTL\",\n",
    "                color=\"Significant_bQTL\"))\n",
    "             +geom_point(alpha=0.3)\n",
    "             +xlab(\"bQTL logratio\")\n",
    "             +ylab(\"POST allele motif scan score - ALT allele motif scan\")\n",
    "             +theme_bw()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EvY4FTmzimV"
   },
   "source": [
    "#### Model predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQqmuTmTzimW"
   },
   "outputs": [],
   "source": [
    "#We plot the model predictions for the POST and ALT alleles\n",
    "# (we examined this plot above, it is reproduced here for context with the other comparisons)\n",
    "\n",
    "print((ggplot(significant_to_score_bqtls,aes(x=\"post_regression_predictions\",\n",
    "                y=\"alt_regression_predictions\"))\n",
    "             +geom_point(alpha=0.3,color=\"#0000FF\")\n",
    "             +xlab(\"POST allele regression model prediction\")\n",
    "             +ylab(\"ALT allele regression model prediction\")\n",
    "             +ggtitle(\"Signicant bQTLs\")\n",
    "             +theme_bw()))\n",
    "print((ggplot(insignificant_to_score_bqtls,aes(x=\"post_regression_predictions\",\n",
    "                y=\"alt_regression_predictions\"))\n",
    "             +geom_point(alpha=0.3,color=\"#FF0000\")\n",
    "             +xlab(\"POST allele regression model prediction\")\n",
    "             +ylab(\"ALT allele regression model prediction\")\n",
    "             +ggtitle(\"Non-Signicant bQTLs\")\n",
    "             +theme_bw()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UMkj8e2zimW"
   },
   "outputs": [],
   "source": [
    "#We plot the logratio for the bQTLs vs the delta in logit space \n",
    "\n",
    "#we extract the fields we need for plotting\n",
    "to_plot=pd.DataFrame({'Significant_bQTL':to_score_bqtls['Significant_bQTL'],\n",
    "                      'logratio':to_score_bqtls['logratio'],\n",
    "                     'delta_regression_predictions':\n",
    "                      to_score_bqtls['post_regression_predictions']-\n",
    "                      to_score_bqtls['alt_regression_predictions']})\n",
    "\n",
    "print((ggplot(to_plot,aes(x=\"logratio\",\n",
    "                y=\"delta_regression_predictions\",\n",
    "                color=\"Significant_bQTL\",\n",
    "                fill=\"Significant_bQTL\",\n",
    "                group=\"Significant_bQTL\"))\n",
    "             +geom_point(alpha=0.3)\n",
    "             +xlab(\"bQTL logratio\")\n",
    "             +ylab(\"POST allele regression prediction - \\nALT allele regression prediction\")\n",
    "             +theme_bw()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpUKBat9zimX"
   },
   "source": [
    "Finally, we restrict our analysis to the subset of bQTL's where the model's prediction changed most dramatically betwen the POST and ALT alleles. For this purpose, we subset the to_score_bqtls to those bQTL's where : \n",
    "\n",
    "* POST prediction > 0.9 and ALT prediction < 0.5\n",
    "or \n",
    "* POST prediction < 0.5 and ALT prediction > 0.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCzn04DgzimX"
   },
   "outputs": [],
   "source": [
    "condition1=(to_score_bqtls['post_regression_predictions']>0.9) & (to_score_bqtls['alt_regression_predictions']<0.5)\n",
    "condition2=(to_score_bqtls['post_regression_predictions']<0.5) & (to_score_bqtls['alt_regression_predictions']>0.9)\n",
    "\n",
    "to_keep=condition1 | condition2 \n",
    "confident_to_score_bqtls=to_score_bqtls[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP98gX1pzimY"
   },
   "outputs": [],
   "source": [
    "confident_to_score_bqtls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Z0sjF4mzimZ"
   },
   "outputs": [],
   "source": [
    "#We plot the model predictions for the POST and ALT alleles\n",
    "# (we examined this plot above, it is reproduced here for context with the other comparisons)\n",
    "\n",
    "print((ggplot(confident_to_score_bqtls,aes(x=\"post_regression_predictions\",\n",
    "                y=\"alt_regression_predictions\",\n",
    "                group=\"Significant_bQTL\",\n",
    "                color=\"Significant_bQTL\"))\n",
    "             +geom_point(alpha=0.5)\n",
    "             +xlab(\"POST allele regression model prediction\")\n",
    "             +ylab(\"ALT allele regression model prediction\")\n",
    "             +scale_color_manual(values=[\"#FF0000\",\"#0000FF\"])\n",
    "             +theme_bw()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXSmTr-ezima"
   },
   "outputs": [],
   "source": [
    "#We plot the logratio for the bQTLs vs the delta in predictions \n",
    "\n",
    "#we extract the fields we need for plotting\n",
    "to_plot=pd.DataFrame({'Significant_bQTL':confident_to_score_bqtls['Significant_bQTL'],\n",
    "                      'logratio':confident_to_score_bqtls['logratio'],\n",
    "                     'delta_regression_predictions':\n",
    "                      confident_to_score_bqtls['post_regression_predictions']-\n",
    "                      confident_to_score_bqtls['alt_regression_predictions']})\n",
    "\n",
    "print((ggplot(to_plot,aes(x=\"logratio\",\n",
    "                y=\"delta_regression_predictions\",\n",
    "                color=\"Significant_bQTL\",\n",
    "                fill=\"Significant_bQTL\",\n",
    "                group=\"Significant_bQTL\"))\n",
    "             +geom_point(alpha=0.3)\n",
    "             +xlab(\"bQTL logratio\")\n",
    "             +ylab(\"POST allele regression logit  - \\nALT allele regression logit\")\n",
    "             +scale_color_manual(values=[\"#FF0000\",\"#0000FF\"])\n",
    "             +theme_bw()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCfHTFdLzimc"
   },
   "source": [
    "Our visualizations of the logratio values vs the delta in motif scan scores and model predictions are quite informative. For the significant bQTL's, we see a positive correlation between logratio and delta in model predictions. However, this correlation is nearly non-existent for the motif scan, suggesting the higher sensitivity of the deep learning model. Let's test this out on a low-affinity transcription factor example: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR4k9rdIzimc"
   },
   "source": [
    "## Deep learning models are able to identify low-affinity TF-binding sites missed by motif scanning. <a name='15'>\n",
    "<a href=#outline>Home</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9doy8Oq1zimc"
   },
   "source": [
    "Let's examine the region **chr5:107857257:107857288**. We have a highly significant bQTL within that region: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTXzqIvNzimc"
   },
   "outputs": [],
   "source": [
    "to_score_bqtls[(to_score_bqtls['Chr']==\"chr5\") & (to_score_bqtls['position']>107857256) & (to_score_bqtls['position']<107857288)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwlfkTz3zimf"
   },
   "source": [
    "Let's extract the one-hot-encoded 1kb region centered at this position and \n",
    "\n",
    "1) interpret the region with our deep learning models\n",
    "\n",
    "2) scan the region with the canonical SPI1 motif\n",
    "\n",
    "We can compare how the two approaches perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyG938pTzimf"
   },
   "outputs": [],
   "source": [
    "bqtl_post_gen=BQTLGenerator(\"SPI1.bQTLs.toScore.txt.gz\",\n",
    "                            \"hg19.genome.fa.gz\",\n",
    "                            \"POSTallele\",\n",
    "                            batch_size=num_to_score)\n",
    "bqtl_alt_gen=BQTLGenerator(\"SPI1.bQTLs.toScore.txt.gz\",\n",
    "                           \"hg19.genome.fa.gz\",\n",
    "                           \"ALTallele\",\n",
    "                           batch_size=num_to_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71kF-udozimg"
   },
   "outputs": [],
   "source": [
    "post_seq=np.expand_dims(bqtl_post_gen[0][1622],axis=0)\n",
    "alt_seq=np.expand_dims(bqtl_alt_gen[0][1622],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IQdEscszimg"
   },
   "outputs": [],
   "source": [
    "post_seq_regression_interpretations=multi_method_interpret(spi1_regression_model,\n",
    "                                           post_seq,\n",
    "                                           0,\n",
    "                                           motif_names=['SPI1B'],\n",
    "                                           pfm=spi1_pfm,\n",
    "                                           GC_fraction=GC_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6T37mmpzimh"
   },
   "outputs": [],
   "source": [
    "plot_all_interpretations([post_seq_regression_interpretations],post_seq,xlim=(450,550),snp_pos=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIKD8hmkzimi"
   },
   "source": [
    "DeepLIFT identifies the region centered at the bQTL as important for predicting accessiblity, and the deepLIFT track matches the PWM for SPI1B quite well. The one exception is position 12 in the PWM -- our sequence has a \"T\" at that \n",
    "position, which both the model and the PWM strongly disfavor. However, the model is sensitive enough to recognize that the region is still a weak-affinity SPI1B site, whereas the motif scan lacks that sensitivity -- the motif scan track returns non-significant scores throughout the 1kb region. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Liux1Th6ziml"
   },
   "source": [
    "Although our motif scan gave random-looking scores, let's see how our scan results compare relative to the \"best possible\" motif hit, the \"worst possible\" motif hit, and an \"average\" region selected from the genome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYUwI8-vziml"
   },
   "outputs": [],
   "source": [
    "#identify indices of the bases with highest probability at each position in the PFM\n",
    "best_match_bases=np.argmax(spi1_pfm,axis=0)\n",
    "worst_match_bases=np.argmin(spi1_pfm,axis=0)\n",
    "mask=np.zeros(spi1_pfm.shape)\n",
    "\n",
    "best_hits=mask.copy() \n",
    "worst_hits=mask.copy() \n",
    "\n",
    "#generate one-hot encoding of the best and worst hits \n",
    "for index in range(mask.shape[1]): \n",
    "    cur_best_base=best_match_bases[index]\n",
    "    cur_worst_base=worst_match_bases[index]\n",
    "    best_hits[cur_best_base,index]=1\n",
    "    worst_hits[cur_worst_base,index]=1\n",
    "\n",
    "#generate a PFM consistent with the genome average base frequencies \n",
    "genome_background=np.tile(np.array([0.26,0.23,0.23,0.26]),(spi1_pfm.shape[1],1)).transpose()\n",
    "\n",
    "#transpose the PFM's and expand dimensions to get a format compatible for motif scanning\n",
    "best_hits=np.expand_dims(np.expand_dims(np.transpose(best_hits),axis=0),axis=0)\n",
    "worst_hits=np.expand_dims(np.expand_dims(np.transpose(worst_hits),axis=0),axis=0)\n",
    "genome_background=np.expand_dims(np.expand_dims(np.transpose(genome_background),axis=0),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDB7MZmPziml"
   },
   "outputs": [],
   "source": [
    "best_score=np.max(get_motif_scores(best_hits,['SPI1'],GC_fraction=GC_fraction,pfm=spi1_pfm,include_rc=False))\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxTXgpWgzimm"
   },
   "outputs": [],
   "source": [
    "worst_score=np.min(get_motif_scores(worst_hits,['SPI1'],GC_fraction=GC_fraction,pfm=spi1_pfm,include_rc=False))\n",
    "print(worst_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6kzJablzimn"
   },
   "outputs": [],
   "source": [
    "genome_background_score=np.max(get_motif_scores(genome_background,['SPI1'],GC_fraction=GC_fraction,pfm=spi1_pfm,include_rc=False))\n",
    "print(genome_background_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8nnqKlCzimp"
   },
   "source": [
    "How does this compare to our observed score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Md3OEF3zimp"
   },
   "outputs": [],
   "source": [
    "post_score=get_motif_scores(post_seq,['SPI1'],GC_fraction=GC_fraction,pfm=spi1_pfm,include_rc=True)\n",
    "print(np.max(post_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7ICjtInzimq"
   },
   "source": [
    "We overlay the best possible motif match, the worst possible motif match, the observed motif score track, and the genome background score track to illustrate that motif scanning does not effectively identify the SPI1 hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqP2-50Hzimq"
   },
   "outputs": [],
   "source": [
    "f,axes=plt.subplots(1,dpi=80,figsize=(20,6))\n",
    "axes.plot(post_score.squeeze(), \"-ko\",label=\"Observed motif scores at low affinity site (1kb region)\")\n",
    "axes.axhline(y=worst_score,color=\"r\",label=\"Worst possible SPI1 score\")\n",
    "axes.axhline(y=best_score,color=\"b\",label=\"Best possible SPI1 score\")\n",
    "axes.axhline(y=genome_background_score,color=\"green\",label=\"Mean genome background  SPI1 score\")\n",
    "axes.axhline(y=np.max(post_score),color=\"orange\",label=\"Max of observed SPI1 scores at low affinity site \")\n",
    "axes.set_xlabel(\"Sequence base\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XyBXLsszimr"
   },
   "source": [
    "In summary, we conclude that the low-affinity SPI1 motif would have been missed by a classical PWM-scanning approach, but is clearly idenfitied via DeepLIFT and ISM analysis on the regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v6zqwHX2G3Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PrimerTutorial 1 - Exploring model architectures for a homotypic motif density simulation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
